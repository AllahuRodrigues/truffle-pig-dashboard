{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23296ff0-ec51-41bf-9783-0a681e4270d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 files to process...\n",
      "--- Processing: Cust By Channel-Ext.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Cust By Channel-New.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Email.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Marketing Channel Breakdown.csv ---\n",
      "❌ Error: \"The following id_vars or value_vars are not present in the DataFrame: ['channel_name', 'year']\"\n",
      "--- Processing: Media Spend by Channel.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Orders By Channel-Ext.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Orders By Channel-New.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Returns.csv ---\n",
      "✅ Success.\n",
      "--- Processing: TOPSHEET.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Web Analytics.csv ---\n",
      "✅ Success.\n",
      "\n",
      "\n",
      "--- Processing Summary ---\n",
      "Successfully processed: 9 files\n",
      "  - Cust By Channel-Ext.csv -> Saved to cleaned_Cust By Channel-Ext.csv\n",
      "  - Cust By Channel-New.csv -> Saved to cleaned_Cust By Channel-New.csv\n",
      "  - Email.csv -> Saved to cleaned_Email.csv\n",
      "  - Media Spend by Channel.csv -> Saved to cleaned_Media Spend by Channel.csv\n",
      "  - Orders By Channel-Ext.csv -> Saved to cleaned_Orders By Channel-Ext.csv\n",
      "  - Orders By Channel-New.csv -> Saved to cleaned_Orders By Channel-New.csv\n",
      "  - Returns.csv -> Saved to cleaned_Returns.csv\n",
      "  - TOPSHEET.csv -> Saved to cleaned_TOPSHEET.csv\n",
      "  - Web Analytics.csv -> Saved to cleaned_Web Analytics.csv\n",
      "\n",
      "Failed to process: 1 files\n",
      "  - Marketing Channel Breakdown.csv: \"The following id_vars or value_vars are not present in the DataFrame: ['channel_name', 'year']\"\n",
      "\n",
      "--- Sample of Cleaned Data (Media Spend by Channel.csv) ---\n",
      "        channel_name   value       date\n",
      "0  Paid Search Media   52392 2025-01-01\n",
      "1  Paid Search Media   33131 2024-01-01\n",
      "2  Paid Search Media   46139 2023-01-01\n",
      "3  Paid Search Media   51972 2022-01-01\n",
      "4  Paid Social Media  110665 2025-01-01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "def clean_and_process_all_files():\n",
    "    \"\"\"\n",
    "    Finds all relevant CSVs in the folder, then loads, cleans, and processes them.\n",
    "    - Cleans currency and percentage strings.\n",
    "    - Reshapes wide-format data to long format.\n",
    "    - Standardizes column names.\n",
    "    - Handles file not found errors gracefully.\n",
    "    - Saves cleaned files to new CSVs.\n",
    "    \"\"\"\n",
    "    # Use glob to find the files in the current directory\n",
    "    file_names = [f for f in glob.glob(\"*.csv\") if not f.startswith('cleaned_')]\n",
    "    \n",
    "    cleaned_dataframes = {}\n",
    "    errors = {}\n",
    "\n",
    "    print(f\"Found {len(file_names)} files to process...\")\n",
    "\n",
    "    # --- Helper Functions ---\n",
    "    def clean_currency(s):\n",
    "        if isinstance(s, str):\n",
    "            s = s.replace('$', '').replace(',', '')\n",
    "            if '(' in s and ')' in s:\n",
    "                s = '-' + s.replace('(', '').replace(')', '')\n",
    "            return pd.to_numeric(s, errors='coerce')\n",
    "        return s\n",
    "\n",
    "    def clean_numeric_string(s):\n",
    "        if isinstance(s, str):\n",
    "            return pd.to_numeric(s.replace(',', ''), errors='coerce')\n",
    "        return s\n",
    "\n",
    "    def clean_percentage(s):\n",
    "        if isinstance(s, str):\n",
    "            return pd.to_numeric(s.replace('%', ''), errors='coerce') / 100.0\n",
    "        return s\n",
    "\n",
    "    for file_name in file_names:\n",
    "        try:\n",
    "            print(f\"--- Processing: {file_name} ---\")\n",
    "            \n",
    "            separator = '\\t' if file_name == \"Marketing Channel Breakdown.csv\" else ','\n",
    "            df = pd.read_csv(file_name, sep=separator)\n",
    "            \n",
    "            original_file_name = file_name # Keep track of the original name\n",
    "            \n",
    "            # Standardize column names\n",
    "            df.columns = [str(col).lower().replace(' ', '_').replace('-', '_') for col in df.columns]\n",
    "\n",
    "            if 'returns' in file_name.lower():\n",
    "                for col in ['gross_sales', 'discounts', 'returns', 'net_sales']:\n",
    "                    df[col] = df[col].apply(clean_currency)\n",
    "                df['month'] = pd.to_datetime(df['month'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "            elif 'email' in file_name.lower():\n",
    "                df.rename(columns={'type_(batch_marketing,_triggered,_transactional)': 'email_type'}, inplace=True)\n",
    "                df['sends'] = df['sends'].apply(clean_numeric_string)\n",
    "                df['clicks'] = df['clicks'].apply(clean_numeric_string)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01', errors='coerce')\n",
    "                df = df[['date', 'email_type', 'sends', 'clicks']]\n",
    "            \n",
    "            elif 'web_analytics' in file_name.lower():\n",
    "                for col in ['added_to_cart_rate', 'reached_checkout_rate', 'checkout_conversion_rate', 'conversion_rate']:\n",
    "                    df[col] = df[col].apply(clean_percentage)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01', errors='coerce')\n",
    "                df.drop(columns=['year', 'month'], inplace=True, errors='ignore')\n",
    "\n",
    "            elif 'channel' in file_name.lower() or 'topsheet' in file_name.lower():\n",
    "                if 'topsheet' in file_name.lower():\n",
    "                    df.rename(columns={'kpi': 'metric', 'data_source': 'source'}, inplace=True)\n",
    "                    id_vars = ['source', 'metric', 'year']\n",
    "                else:\n",
    "                    df.rename(columns={'channel': 'channel_name'}, inplace=True)\n",
    "                    id_vars = ['channel_name', 'year']\n",
    "                \n",
    "                month_cols = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']\n",
    "                value_vars = [col for col in month_cols if col in df.columns]\n",
    "                \n",
    "                for col in value_vars:\n",
    "                    df[col] = df[col].astype(str).str.replace(',', '').str.replace('$', '').str.replace('%', '')\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "                df = df.melt(id_vars=id_vars, value_vars=value_vars, var_name='month', value_name='value')\n",
    "                \n",
    "                month_map = {name: i+1 for i, name in enumerate(month_cols)}\n",
    "                df['month_num'] = df['month'].str.lower().map(month_map)\n",
    "                df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
    "                df.dropna(subset=['year', 'month_num'], inplace=True)\n",
    "                df['year'] = df['year'].astype(int)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month_num'].astype(str) + '-01', errors='coerce')\n",
    "                df.drop(columns=['year', 'month', 'month_num'], inplace=True, errors='ignore')\n",
    "            \n",
    "            elif 'marketing_channel_breakdown' in file_name.lower():\n",
    "                 # This file might have a year as the first column, let's rename it\n",
    "                df.rename(columns={df.columns[0]: 'year'}, inplace=True)\n",
    "                # Add cleaning logic for its specific currency/numeric columns if needed\n",
    "                for col in ['ad_spend', 'gross_discount_(shopify)', 'sessions', 'clicks', 'orders', 'new_customers']:\n",
    "                    if col in df.columns:\n",
    "                        df[col] = df[col].apply(clean_numeric_string)\n",
    "                for col in ['ctr', 'conversion_rate']:\n",
    "                     if col in df.columns:\n",
    "                        df[col] = df[col].apply(clean_percentage)\n",
    "\n",
    "            cleaned_dataframes[original_file_name] = df\n",
    "            print(f\"✅ Success.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            errors[original_file_name] = str(e)\n",
    "            print(f\"❌ Error: {e}\")\n",
    "\n",
    "    print(\"\\n\\n--- Processing Summary ---\")\n",
    "    if cleaned_dataframes:\n",
    "        print(f\"Successfully processed: {len(cleaned_dataframes)} files\")\n",
    "        for f in cleaned_dataframes.keys():\n",
    "            cleaned_file_name = f\"cleaned_{f}\"\n",
    "            cleaned_dataframes[f].to_csv(cleaned_file_name, index=False)\n",
    "            print(f\"  - {f} -> Saved to {cleaned_file_name}\")\n",
    "\n",
    "    if errors:\n",
    "        print(f\"\\nFailed to process: {len(errors)} files\")\n",
    "        for f, reason in errors.items():\n",
    "            print(f\"  - {f}: {reason}\")\n",
    "    \n",
    "    return cleaned_dataframes, errors\n",
    "\n",
    "# --- Run the script ---\n",
    "if __name__ == '__main__':\n",
    "    cleaned_data, error_log = clean_and_process_all_files()\n",
    "\n",
    "    # As an example, display the first 5 rows of a cleaned, reshaped file\n",
    "    if 'Media Spend by Channel.csv' in cleaned_data:\n",
    "        print(\"\\n--- Sample of Cleaned Data (Media Spend by Channel.csv) ---\")\n",
    "        print(cleaned_data['Media Spend by Channel.csv'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03c33f34-8953-44fd-bed7-7ad27d60455d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analysis for cleaned_Cust By Channel-Ext.csv ---\n",
      "\n",
      "\n",
      "--- Data Types and Non-Null Counts ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 648 entries, 0 to 647\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   channel_name  648 non-null    object\n",
      " 1   value         648 non-null    int64 \n",
      " 2   date          648 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 15.3+ KB\n",
      "\n",
      "\n",
      "--- Duplicates Check ---\n",
      "Number of duplicate rows found: 0\n",
      "\n",
      "\n",
      "--- Descriptive Statistics ---\n",
      "Could not generate full descriptive statistics. Error: NDFrame.describe() got an unexpected keyword argument 'datetime_is_numeric'\n",
      "\n",
      "\n",
      "--- Unique Channel Names ---\n",
      "['Paid Search' 'Paid Social' 'Affiliate' 'Display' 'Email' 'SMS'\n",
      " 'Organic Search' 'Direct' 'Unattributed' 'Other' 'Organic Social']\n",
      "\n",
      "\n",
      "--- Negative Value Check ---\n",
      "No negative customer counts found. That's good.\n",
      "\n",
      "\n",
      "--- Date Range Check ---\n",
      "Date range: 2021-01-01 to 2025-12-01\n",
      "MISTAKE FOUND: There are 50 dates in the future (after July 1, 2025).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    # Load the user-provided cleaned file\n",
    "    file_path = \"cleaned_Cust By Channel-Ext.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    print(f\"--- Analysis for {file_path} ---\")\n",
    "\n",
    "    # --- 1. Check Data Types and Null Values ---\n",
    "    print(\"\\n\\n--- Data Types and Non-Null Counts ---\")\n",
    "    # Use a buffer to capture the info() output as a string\n",
    "    from io import StringIO\n",
    "    buffer = StringIO()\n",
    "    df.info(buf=buffer)\n",
    "    info_str = buffer.getvalue()\n",
    "    print(info_str)\n",
    "\n",
    "    # --- 2. Check for Duplicates ---\n",
    "    duplicate_rows = df.duplicated().sum()\n",
    "    print(f\"\\n--- Duplicates Check ---\")\n",
    "    print(f\"Number of duplicate rows found: {duplicate_rows}\")\n",
    "\n",
    "\n",
    "    # --- 3. Examine Descriptive Statistics ---\n",
    "    print(\"\\n\\n--- Descriptive Statistics ---\")\n",
    "    # The datetime_is_numeric=True is needed for newer pandas versions\n",
    "    try:\n",
    "        # Temporarily convert date for describe if it's object\n",
    "        if df['date'].dtype == 'object':\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "        print(df.describe(include='all', datetime_is_numeric=True))\n",
    "    except Exception as e:\n",
    "        print(f\"Could not generate full descriptive statistics. Error: {e}\")\n",
    "\n",
    "\n",
    "    # --- 4. Deep Dive into Specific Columns ---\n",
    "\n",
    "    # Channel Name consistency\n",
    "    print(\"\\n\\n--- Unique Channel Names ---\")\n",
    "    unique_channels = df['channel_name'].unique()\n",
    "    print(unique_channels)\n",
    "\n",
    "    # Check for negative values where they shouldn't be\n",
    "    print(\"\\n\\n--- Negative Value Check ---\")\n",
    "    if 'value' in df.columns and pd.api.types.is_numeric_dtype(df['value']):\n",
    "        negative_values = df[df['value'] < 0].shape[0]\n",
    "        if negative_values > 0:\n",
    "            print(f\"MISTAKE FOUND: There are {negative_values} rows with negative customer counts.\")\n",
    "        else:\n",
    "            print(\"No negative customer counts found. That's good.\")\n",
    "    else:\n",
    "        print(\"Could not perform negative value check on 'value' column.\")\n",
    "\n",
    "    # Check the date range\n",
    "    print(\"\\n\\n--- Date Range Check ---\")\n",
    "    if 'date' in df.columns:\n",
    "        try:\n",
    "            # Ensure 'date' column is datetime\n",
    "            if df['date'].dtype != '<M8[ns]':\n",
    "                 df['date'] = pd.to_datetime(df['date'])\n",
    "            \n",
    "            min_date = df['date'].min().strftime('%Y-%m-%d')\n",
    "            max_date = df['date'].max().strftime('%Y-%m-%d')\n",
    "            print(f\"Date range: {min_date} to {max_date}\")\n",
    "\n",
    "            # Check if any dates are in the future\n",
    "            # Using a fixed date for reproducibility based on conversation context\n",
    "            future_dates = df[df['date'] > pd.to_datetime(\"2025-07-01\")].shape[0]\n",
    "            if future_dates > 0:\n",
    "                 print(f\"MISTAKE FOUND: There are {future_dates} dates in the future (after July 1, 2025).\")\n",
    "            else:\n",
    "                 print(\"No future dates found. That's good.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not perform date analysis. Error: {e}\")\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: The file '{file_path}' was not found. Please ensure it's in the same directory as your notebook.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during analysis: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f6a383f-56f0-4bb3-a7b1-986726e9f6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the cleaning process for 9 files...\n",
      "--- Processing: Cust By Channel-Ext.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Cust By Channel-New.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Email.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Media Spend by Channel.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Orders By Channel-Ext.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Orders By Channel-New.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Returns.csv ---\n",
      "✅ Success.\n",
      "--- Processing: TOPSHEET.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Web Analytics.csv ---\n",
      "✅ Success.\n",
      "\n",
      "\n",
      "--- Processing Summary ---\n",
      "Successfully processed: 9 files\n",
      "  - Cust By Channel-Ext.csv -> Saved to cleaned_Cust By Channel-Ext.csv\n",
      "  - Cust By Channel-New.csv -> Saved to cleaned_Cust By Channel-New.csv\n",
      "  - Email.csv -> Saved to cleaned_Email.csv\n",
      "  - Media Spend by Channel.csv -> Saved to cleaned_Media Spend by Channel.csv\n",
      "  - Orders By Channel-Ext.csv -> Saved to cleaned_Orders By Channel-Ext.csv\n",
      "  - Orders By Channel-New.csv -> Saved to cleaned_Orders By Channel-New.csv\n",
      "  - Returns.csv -> Saved to cleaned_Returns.csv\n",
      "  - TOPSHEET.csv -> Saved to cleaned_TOPSHEET.csv\n",
      "  - Web Analytics.csv -> Saved to cleaned_Web Analytics.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "\n",
    "def clean_all_data_files_final():\n",
    "    \"\"\"\n",
    "    Finds all raw CSVs in the folder, then loads, cleans, reshapes, and saves them.\n",
    "    This version includes specific fixes for the marketing file and date formats.\n",
    "    \"\"\"\n",
    "    # Define all the expected raw filenames\n",
    "    file_names = [\n",
    "        \"Cust By Channel-Ext.csv\", \"Cust By Channel-New.csv\", \"Email.csv\",\n",
    "        \"Media Spend by Channel.csv\",\n",
    "        \"Orders By Channel-Ext.csv\", \"Orders By Channel-New.csv\",\n",
    "        \"Returns.csv\", \"TOPSHEET.csv\", \"Web Analytics.csv\"\n",
    "    ]\n",
    "    \n",
    "    cleaned_dataframes = {}\n",
    "    errors = {}\n",
    "\n",
    "    print(f\"Starting the cleaning process for {len(file_names)} files...\")\n",
    "\n",
    "    # --- Helper Functions ---\n",
    "    def clean_currency(s):\n",
    "        if not isinstance(s, str): return pd.to_numeric(s, errors='coerce')\n",
    "        s = s.replace('$', '').replace(',', '').strip()\n",
    "        if '(' in s and ')' in s:\n",
    "            s = '-' + s.replace('(', '').replace(')', '')\n",
    "        return pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "    def clean_percentage(s):\n",
    "        if not isinstance(s, str): return pd.to_numeric(s, errors='coerce')\n",
    "        return pd.to_numeric(s.replace('%', '').replace('\"', '').strip(), errors='coerce') / 100.0\n",
    "\n",
    "    def clean_numeric(s):\n",
    "        if not isinstance(s, str): return pd.to_numeric(s, errors='coerce')\n",
    "        return pd.to_numeric(s.replace(',', '').strip(), errors='coerce')\n",
    "\n",
    "    for file_name in file_names:\n",
    "        try:\n",
    "            print(f\"--- Processing: {file_name} ---\")\n",
    "            \n",
    "            # --- File Loading and Parsing ---\n",
    "            if file_name == \"Marketing Channel Breakdown.csv\":\n",
    "                # Manual parsing for the most problematic file\n",
    "                with open(file_name, 'r', encoding='utf-8') as f:\n",
    "                    lines = f.readlines()\n",
    "                header = [h.strip() for h in lines[0].split('\\t')]\n",
    "                rows = [line.strip().split('\\t') for line in lines[1:]]\n",
    "                df = pd.DataFrame(rows, columns=header)\n",
    "            else:\n",
    "                df = pd.read_csv(file_name)\n",
    "\n",
    "            # --- Cleaning and Transformation ---\n",
    "            original_file_name = file_name\n",
    "            df.columns = [str(col).lower().replace(' ', '_').replace('-', '_') for col in df.columns]\n",
    "\n",
    "            if 'marketing_channel_breakdown' in file_name.lower():\n",
    "                df.rename(columns={df.columns[0]: 'year_period'}, inplace=True)\n",
    "                for col in ['ad_spend', 'gross_discount_(shopify)']: df[col] = df[col].apply(clean_currency)\n",
    "                for col in ['sessions', 'clicks', 'orders', 'new_customers']: df[col] = df[col].apply(clean_numeric)\n",
    "                for col in ['ctr', 'conversion_rate']: df[col] = df[col].apply(clean_percentage)\n",
    "                df['year'] = df['year_period'].apply(lambda x: str(x).split(' ')[0])\n",
    "\n",
    "            elif 'returns' in file_name.lower():\n",
    "                for col in ['gross_sales', 'discounts', 'returns', 'net_sales']: df[col] = df[col].apply(clean_currency)\n",
    "                df['month'] = pd.to_datetime(df['month'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "            elif 'email' in file_name.lower():\n",
    "                df.rename(columns={'type_(batch_marketing,_triggered,_transactional)': 'email_type'}, inplace=True)\n",
    "                for col in ['sends', 'clicks']: df[col] = df[col].apply(clean_numeric)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01', errors='coerce')\n",
    "                df = df[['date', 'email_type', 'sends', 'clicks']]\n",
    "\n",
    "            elif 'web_analytics' in file_name.lower():\n",
    "                for col in ['added_to_cart_rate', 'reached_checkout_rate', 'checkout_conversion_rate', 'conversion_rate']: df[col] = df[col].apply(clean_percentage)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01', errors='coerce')\n",
    "                df.drop(columns=['year', 'month'], inplace=True, errors='ignore')\n",
    "\n",
    "            elif 'channel' in file_name.lower() or 'topsheet' in file_name.lower():\n",
    "                id_vars = []\n",
    "                if 'topsheet' in file_name.lower():\n",
    "                    df.rename(columns={'kpi': 'metric', 'data_source': 'source'}, inplace=True)\n",
    "                    id_vars = [c for c in ['source', 'metric', 'year'] if c in df.columns]\n",
    "                else:\n",
    "                    df.rename(columns={'channel': 'channel_name'}, inplace=True)\n",
    "                    id_vars = [c for c in ['channel_name', 'year'] if c in df.columns]\n",
    "\n",
    "                month_cols = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']\n",
    "                value_vars = [col for col in month_cols if col in df.columns]\n",
    "                \n",
    "                for col in value_vars: df[col] = df[col].apply(clean_numeric)\n",
    "\n",
    "                df = df.melt(id_vars=id_vars, value_vars=value_vars, var_name='month', value_name='value')\n",
    "                \n",
    "                month_map = {name: i+1 for i, name in enumerate(month_cols)}\n",
    "                df['month_num'] = df['month'].str.lower().map(month_map)\n",
    "                df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
    "                df.dropna(subset=['year', 'month_num'], inplace=True)\n",
    "                df['year'] = df['year'].astype(int)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month_num'].astype(str) + '-01', errors='coerce')\n",
    "                df.drop(columns=['year', 'month', 'month_num'], inplace=True, errors='ignore')\n",
    "\n",
    "            cleaned_dataframes[original_file_name] = df\n",
    "            print(f\"✅ Success.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            errors[original_file_name] = str(e)\n",
    "            print(f\"❌ Error: {e}\")\n",
    "\n",
    "    print(\"\\n\\n--- Processing Summary ---\")\n",
    "    if cleaned_dataframes:\n",
    "        print(f\"Successfully processed: {len(cleaned_dataframes)} files\")\n",
    "        for f in cleaned_dataframes.keys():\n",
    "            cleaned_file_name = f\"cleaned_{f}\"\n",
    "            cleaned_dataframes[f].to_csv(cleaned_file_name, index=False)\n",
    "            print(f\"  - {f} -> Saved to {cleaned_file_name}\")\n",
    "\n",
    "    if errors:\n",
    "        print(f\"\\nFailed to process: {len(errors)} files\")\n",
    "        for f, reason in errors.items():\n",
    "            print(f\"  - {f}: {reason}\")\n",
    "    \n",
    "    return cleaned_dataframes, errors\n",
    "\n",
    "# --- Run the entire cleaning process ---\n",
    "if __name__ == '__main__':\n",
    "    cleaned_data, error_log = clean_all_data_files_final()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93ca421e-4df5-410e-8536-9d37f94a943f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the cleaning process for 1 files...\n",
      "--- Processing: Media Spend by Channel.csv ---\n",
      "✅ Success.\n",
      "\n",
      "\n",
      "--- Processing Summary ---\n",
      "Successfully processed: 1 files\n",
      "  - Media Spend by Channel.csv -> Saved to cleaned_Media Spend by Channel.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "\n",
    "def clean_all_data_files_final():\n",
    "    \"\"\"\n",
    "    Finds all raw CSVs in the folder, then loads, cleans, reshapes, and saves them.\n",
    "    This version includes specific fixes for the marketing file and date formats.\n",
    "    \"\"\"\n",
    "    # Define all the expected raw filenames\n",
    "    file_names = [\n",
    "        \"Media Spend by Channel.csv\"\n",
    "    ]\n",
    "    \n",
    "    cleaned_dataframes = {}\n",
    "    errors = {}\n",
    "\n",
    "    print(f\"Starting the cleaning process for {len(file_names)} files...\")\n",
    "\n",
    "    # --- Helper Functions ---\n",
    "    def clean_currency(s):\n",
    "        if not isinstance(s, str): return pd.to_numeric(s, errors='coerce')\n",
    "        s = s.replace('$', '').replace(',', '').strip()\n",
    "        if '(' in s and ')' in s:\n",
    "            s = '-' + s.replace('(', '').replace(')', '')\n",
    "        return pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "    def clean_percentage(s):\n",
    "        if not isinstance(s, str): return pd.to_numeric(s, errors='coerce')\n",
    "        return pd.to_numeric(s.replace('%', '').replace('\"', '').strip(), errors='coerce') / 100.0\n",
    "\n",
    "    def clean_numeric(s):\n",
    "        if not isinstance(s, str): return pd.to_numeric(s, errors='coerce')\n",
    "        return pd.to_numeric(s.replace(',', '').strip(), errors='coerce')\n",
    "\n",
    "    for file_name in file_names:\n",
    "        try:\n",
    "            print(f\"--- Processing: {file_name} ---\")\n",
    "            \n",
    "            # --- File Loading and Parsing ---\n",
    "            if file_name == \"Marketing Channel Breakdown.csv\":\n",
    "                # Manual parsing for the most problematic file\n",
    "                with open(file_name, 'r', encoding='utf-8') as f:\n",
    "                    lines = f.readlines()\n",
    "                header = [h.strip() for h in lines[0].split('\\t')]\n",
    "                rows = [line.strip().split('\\t') for line in lines[1:]]\n",
    "                df = pd.DataFrame(rows, columns=header)\n",
    "            else:\n",
    "                df = pd.read_csv(file_name)\n",
    "\n",
    "            # --- Cleaning and Transformation ---\n",
    "            original_file_name = file_name\n",
    "            df.columns = [str(col).lower().replace(' ', '_').replace('-', '_') for col in df.columns]\n",
    "\n",
    "            if 'marketing_channel_breakdown' in file_name.lower():\n",
    "                df.rename(columns={df.columns[0]: 'year_period'}, inplace=True)\n",
    "                for col in ['ad_spend', 'gross_discount_(shopify)']: df[col] = df[col].apply(clean_currency)\n",
    "                for col in ['sessions', 'clicks', 'orders', 'new_customers']: df[col] = df[col].apply(clean_numeric)\n",
    "                for col in ['ctr', 'conversion_rate']: df[col] = df[col].apply(clean_percentage)\n",
    "                df['year'] = df['year_period'].apply(lambda x: str(x).split(' ')[0])\n",
    "\n",
    "            elif 'returns' in file_name.lower():\n",
    "                for col in ['gross_sales', 'discounts', 'returns', 'net_sales']: df[col] = df[col].apply(clean_currency)\n",
    "                df['month'] = pd.to_datetime(df['month'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "            elif 'email' in file_name.lower():\n",
    "                df.rename(columns={'type_(batch_marketing,_triggered,_transactional)': 'email_type'}, inplace=True)\n",
    "                for col in ['sends', 'clicks']: df[col] = df[col].apply(clean_numeric)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01', errors='coerce')\n",
    "                df = df[['date', 'email_type', 'sends', 'clicks']]\n",
    "\n",
    "            elif 'web_analytics' in file_name.lower():\n",
    "                for col in ['added_to_cart_rate', 'reached_checkout_rate', 'checkout_conversion_rate', 'conversion_rate']: df[col] = df[col].apply(clean_percentage)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01', errors='coerce')\n",
    "                df.drop(columns=['year', 'month'], inplace=True, errors='ignore')\n",
    "\n",
    "            elif 'channel' in file_name.lower() or 'topsheet' in file_name.lower():\n",
    "                id_vars = []\n",
    "                if 'topsheet' in file_name.lower():\n",
    "                    df.rename(columns={'kpi': 'metric', 'data_source': 'source'}, inplace=True)\n",
    "                    id_vars = [c for c in ['source', 'metric', 'year'] if c in df.columns]\n",
    "                else:\n",
    "                    df.rename(columns={'channel': 'channel_name'}, inplace=True)\n",
    "                    id_vars = [c for c in ['channel_name', 'year'] if c in df.columns]\n",
    "\n",
    "                month_cols = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']\n",
    "                value_vars = [col for col in month_cols if col in df.columns]\n",
    "                \n",
    "                # CORRECTED: Use clean_currency for files like media spend that have dollar values.\n",
    "                # This is more robust than clean_numeric for these specific files.\n",
    "                for col in value_vars: df[col] = df[col].apply(clean_currency)\n",
    "\n",
    "                df = df.melt(id_vars=id_vars, value_vars=value_vars, var_name='month', value_name='value')\n",
    "                \n",
    "                month_map = {name: i+1 for i, name in enumerate(month_cols)}\n",
    "                df['month_num'] = df['month'].str.lower().map(month_map)\n",
    "                df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
    "                df.dropna(subset=['year', 'month_num'], inplace=True)\n",
    "                df['year'] = df['year'].astype(int)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month_num'].astype(str) + '-01', errors='coerce')\n",
    "                df.drop(columns=['year', 'month', 'month_num'], inplace=True, errors='ignore')\n",
    "\n",
    "            cleaned_dataframes[original_file_name] = df\n",
    "            print(f\"✅ Success.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            errors[original_file_name] = str(e)\n",
    "            print(f\"❌ Error: {e}\")\n",
    "\n",
    "    print(\"\\n\\n--- Processing Summary ---\")\n",
    "    if cleaned_dataframes:\n",
    "        print(f\"Successfully processed: {len(cleaned_dataframes)} files\")\n",
    "        for f in cleaned_dataframes.keys():\n",
    "            cleaned_file_name = f\"cleaned_{f}\"\n",
    "            cleaned_dataframes[f].to_csv(cleaned_file_name, index=False)\n",
    "            print(f\"  - {f} -> Saved to {cleaned_file_name}\")\n",
    "\n",
    "    if errors:\n",
    "        print(f\"\\nFailed to process: {len(errors)} files\")\n",
    "        for f, reason in errors.items():\n",
    "            print(f\"  - {f}: {reason}\")\n",
    "    \n",
    "    return cleaned_dataframes, errors\n",
    "\n",
    "# --- Run the entire cleaning process ---\n",
    "if __name__ == '__main__':\n",
    "    cleaned_data, error_log = clean_all_data_files_final()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18cb2a89-503e-45cf-aa70-216f18f31671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the cleaning process for 1 files...\n",
      "--- Processing: Email.csv ---\n",
      "✅ Success.\n",
      "\n",
      "\n",
      "--- Processing Summary ---\n",
      "Successfully processed: 1 files\n",
      "  - Email.csv -> Saved to cleaned_Email.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "\n",
    "def clean_all_data_files_final():\n",
    "    \"\"\"\n",
    "    Finds all raw CSVs in the folder, then loads, cleans, reshapes, and saves them.\n",
    "    This version includes specific fixes for the marketing file and date formats.\n",
    "    \"\"\"\n",
    "    # Define all the expected raw filenames\n",
    "    file_names = [\n",
    "        \"Email.csv\"\n",
    "    ]\n",
    "    \n",
    "    cleaned_dataframes = {}\n",
    "    errors = {}\n",
    "\n",
    "    print(f\"Starting the cleaning process for {len(file_names)} files...\")\n",
    "\n",
    "    # --- Helper Functions ---\n",
    "    def clean_currency(s):\n",
    "        if not isinstance(s, str): return pd.to_numeric(s, errors='coerce')\n",
    "        s = s.replace('$', '').replace(',', '').strip()\n",
    "        if '(' in s and ')' in s:\n",
    "            s = '-' + s.replace('(', '').replace(')', '')\n",
    "        return pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "    def clean_percentage(s):\n",
    "        if not isinstance(s, str): return pd.to_numeric(s, errors='coerce')\n",
    "        return pd.to_numeric(s.replace('%', '').replace('\"', '').strip(), errors='coerce') / 100.0\n",
    "\n",
    "    def clean_numeric(s):\n",
    "        if not isinstance(s, str): return pd.to_numeric(s, errors='coerce')\n",
    "        return pd.to_numeric(s.replace(',', '').strip(), errors='coerce')\n",
    "\n",
    "    for file_name in file_names:\n",
    "        try:\n",
    "            print(f\"--- Processing: {file_name} ---\")\n",
    "            \n",
    "            # --- File Loading and Parsing ---\n",
    "            if file_name == \"Marketing Channel Breakdown.csv\":\n",
    "                # Manual parsing for the most problematic file\n",
    "                with open(file_name, 'r', encoding='utf-8') as f:\n",
    "                    lines = f.readlines()\n",
    "                header = [h.strip() for h in lines[0].split('\\t')]\n",
    "                rows = [line.strip().split('\\t') for line in lines[1:]]\n",
    "                df = pd.DataFrame(rows, columns=header)\n",
    "            else:\n",
    "                df = pd.read_csv(file_name)\n",
    "\n",
    "            # --- Cleaning and Transformation ---\n",
    "            original_file_name = file_name\n",
    "            df.columns = [str(col).lower().replace(' ', '_').replace('-', '_') for col in df.columns]\n",
    "\n",
    "            if 'marketing_channel_breakdown' in file_name.lower():\n",
    "                df.rename(columns={df.columns[0]: 'year_period'}, inplace=True)\n",
    "                for col in ['ad_spend', 'gross_discount_(shopify)']: df[col] = df[col].apply(clean_currency)\n",
    "                for col in ['sessions', 'clicks', 'orders', 'new_customers']: df[col] = df[col].apply(clean_numeric)\n",
    "                for col in ['ctr', 'conversion_rate']: df[col] = df[col].apply(clean_percentage)\n",
    "                df['year'] = df['year_period'].apply(lambda x: str(x).split(' ')[0])\n",
    "\n",
    "            elif 'returns' in file_name.lower():\n",
    "                for col in ['gross_sales', 'discounts', 'returns', 'net_sales']: df[col] = df[col].apply(clean_currency)\n",
    "                df['month'] = pd.to_datetime(df['month'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "            elif 'email' in file_name.lower():\n",
    "                df.rename(columns={'type_(batch_marketing,_triggered,_transactional)': 'email_type'}, inplace=True)\n",
    "                for col in ['sends', 'clicks']: df[col] = df[col].apply(clean_numeric)\n",
    "                \n",
    "                # Remove pre-calculated \"Total\" rows to avoid double-counting\n",
    "                df = df[df['email_type'] != 'Total'].copy()\n",
    "                \n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01', errors='coerce')\n",
    "                df = df[['date', 'email_type', 'sends', 'clicks']]\n",
    "\n",
    "            elif 'web_analytics' in file_name.lower():\n",
    "                for col in ['added_to_cart_rate', 'reached_checkout_rate', 'checkout_conversion_rate', 'conversion_rate']: df[col] = df[col].apply(clean_percentage)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01', errors='coerce')\n",
    "                df.drop(columns=['year', 'month'], inplace=True, errors='ignore')\n",
    "\n",
    "            elif 'channel' in file_name.lower() or 'topsheet' in file_name.lower():\n",
    "                id_vars = []\n",
    "                if 'topsheet' in file_name.lower():\n",
    "                    df.rename(columns={'kpi': 'metric', 'data_source': 'source'}, inplace=True)\n",
    "                    id_vars = [c for c in ['source', 'metric', 'year'] if c in df.columns]\n",
    "                else:\n",
    "                    df.rename(columns={'channel': 'channel_name'}, inplace=True)\n",
    "                    id_vars = [c for c in ['channel_name', 'year'] if c in df.columns]\n",
    "\n",
    "                month_cols = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']\n",
    "                value_vars = [col for col in month_cols if col in df.columns]\n",
    "                \n",
    "                # CORRECTED: Use clean_currency for files like media spend that have dollar values.\n",
    "                # This is more robust than clean_numeric for these specific files.\n",
    "                for col in value_vars: df[col] = df[col].apply(clean_currency)\n",
    "\n",
    "                df = df.melt(id_vars=id_vars, value_vars=value_vars, var_name='month', value_name='value')\n",
    "                \n",
    "                month_map = {name: i+1 for i, name in enumerate(month_cols)}\n",
    "                df['month_num'] = df['month'].str.lower().map(month_map)\n",
    "                df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
    "                df.dropna(subset=['year', 'month_num'], inplace=True)\n",
    "                df['year'] = df['year'].astype(int)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month_num'].astype(str) + '-01', errors='coerce')\n",
    "                df.drop(columns=['year', 'month', 'month_num'], inplace=True, errors='ignore')\n",
    "\n",
    "            cleaned_dataframes[original_file_name] = df\n",
    "            print(f\"✅ Success.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            errors[original_file_name] = str(e)\n",
    "            print(f\"❌ Error: {e}\")\n",
    "\n",
    "    print(\"\\n\\n--- Processing Summary ---\")\n",
    "    if cleaned_dataframes:\n",
    "        print(f\"Successfully processed: {len(cleaned_dataframes)} files\")\n",
    "        for f in cleaned_dataframes.keys():\n",
    "            cleaned_file_name = f\"cleaned_{f}\"\n",
    "            cleaned_dataframes[f].to_csv(cleaned_file_name, index=False)\n",
    "            print(f\"  - {f} -> Saved to {cleaned_file_name}\")\n",
    "\n",
    "    if errors:\n",
    "        print(f\"\\nFailed to process: {len(errors)} files\")\n",
    "        for f, reason in errors.items():\n",
    "            print(f\"  - {f}: {reason}\")\n",
    "    \n",
    "    return cleaned_dataframes, errors\n",
    "\n",
    "# --- Run the entire cleaning process ---\n",
    "if __name__ == '__main__':\n",
    "    cleaned_data, error_log = clean_all_data_files_final()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "607cf2a3-0890-4cf6-b8d4-388ebc69165b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the cleaning process for 1 files...\n",
      "--- Processing: Web Analytics.csv ---\n",
      "✅ Success.\n",
      "\n",
      "\n",
      "--- Processing Summary ---\n",
      "Successfully processed: 1 files\n",
      "  - Web Analytics.csv -> Saved to cleaned_Web Analytics.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "\n",
    "def clean_all_data_files_final():\n",
    "    \"\"\"\n",
    "    Finds all raw CSVs in the folder, then loads, cleans, reshapes, and saves them.\n",
    "    This version includes specific fixes for the marketing file and date formats.\n",
    "    \"\"\"\n",
    "    # Define all the expected raw filenames\n",
    "    file_names = [\n",
    "        \"Web Analytics.csv\"\n",
    "    ]\n",
    "    \n",
    "    cleaned_dataframes = {}\n",
    "    errors = {}\n",
    "\n",
    "    print(f\"Starting the cleaning process for {len(file_names)} files...\")\n",
    "\n",
    "    # --- Helper Functions ---\n",
    "    def clean_currency(s):\n",
    "        if not isinstance(s, str): return pd.to_numeric(s, errors='coerce')\n",
    "        s = s.replace('$', '').replace(',', '').strip()\n",
    "        if '(' in s and ')' in s:\n",
    "            s = '-' + s.replace('(', '').replace(')', '')\n",
    "        return pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "    def clean_percentage(s):\n",
    "        if not isinstance(s, str): return pd.to_numeric(s, errors='coerce')\n",
    "        return pd.to_numeric(s.replace('%', '').replace('\"', '').strip(), errors='coerce') / 100.0\n",
    "\n",
    "    def clean_numeric(s):\n",
    "        if not isinstance(s, str): return pd.to_numeric(s, errors='coerce')\n",
    "        return pd.to_numeric(s.replace(',', '').strip(), errors='coerce')\n",
    "\n",
    "    for file_name in file_names:\n",
    "        try:\n",
    "            print(f\"--- Processing: {file_name} ---\")\n",
    "            \n",
    "            # --- File Loading and Parsing ---\n",
    "            if file_name == \"Marketing Channel Breakdown.csv\":\n",
    "                # Manual parsing for the most problematic file\n",
    "                with open(file_name, 'r', encoding='utf-8') as f:\n",
    "                    lines = f.readlines()\n",
    "                header = [h.strip() for h in lines[0].split('\\t')]\n",
    "                rows = [line.strip().split('\\t') for line in lines[1:]]\n",
    "                df = pd.DataFrame(rows, columns=header)\n",
    "            else:\n",
    "                df = pd.read_csv(file_name)\n",
    "\n",
    "            # --- Cleaning and Transformation ---\n",
    "            original_file_name = file_name\n",
    "            df.columns = [str(col).lower().replace(' ', '_').replace('-', '_') for col in df.columns]\n",
    "\n",
    "            if 'marketing_channel_breakdown' in file_name.lower():\n",
    "                df.rename(columns={df.columns[0]: 'year_period'}, inplace=True)\n",
    "                for col in ['ad_spend', 'gross_discount_(shopify)']: df[col] = df[col].apply(clean_currency)\n",
    "                for col in ['sessions', 'clicks', 'orders', 'new_customers']: df[col] = df[col].apply(clean_numeric)\n",
    "                for col in ['ctr', 'conversion_rate']: df[col] = df[col].apply(clean_percentage)\n",
    "                df['year'] = df['year_period'].apply(lambda x: str(x).split(' ')[0])\n",
    "\n",
    "            elif 'returns' in file_name.lower():\n",
    "                for col in ['gross_sales', 'discounts', 'returns', 'net_sales']: df[col] = df[col].apply(clean_currency)\n",
    "                df['month'] = pd.to_datetime(df['month'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "            elif 'email' in file_name.lower():\n",
    "                df.rename(columns={'type_(batch_marketing,_triggered,_transactional)': 'email_type'}, inplace=True)\n",
    "                for col in ['sends', 'clicks']: df[col] = df[col].apply(clean_numeric)\n",
    "                \n",
    "                # Remove pre-calculated \"Total\" rows to avoid double-counting\n",
    "                df = df[df['email_type'] != 'Total'].copy()\n",
    "                \n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01', errors='coerce')\n",
    "                df = df[['date', 'email_type', 'sends', 'clicks']]\n",
    "\n",
    "            elif 'web_analytics' in file_name.lower():\n",
    "                for col in ['added_to_cart_rate', 'reached_checkout_rate', 'checkout_conversion_rate', 'conversion_rate']: df[col] = df[col].apply(clean_percentage)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01', errors='coerce')\n",
    "                df.drop(columns=['year', 'month'], inplace=True, errors='ignore')\n",
    "\n",
    "            elif 'channel' in file_name.lower() or 'topsheet' in file_name.lower():\n",
    "                id_vars = []\n",
    "                if 'topsheet' in file_name.lower():\n",
    "                    df.rename(columns={'kpi': 'metric', 'data_source': 'source'}, inplace=True)\n",
    "                    id_vars = [c for c in ['source', 'metric', 'year'] if c in df.columns]\n",
    "                else:\n",
    "                    df.rename(columns={'channel': 'channel_name'}, inplace=True)\n",
    "                    id_vars = [c for c in ['channel_name', 'year'] if c in df.columns]\n",
    "\n",
    "                month_cols = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']\n",
    "                value_vars = [col for col in month_cols if col in df.columns]\n",
    "                \n",
    "                # CORRECTED: Use clean_currency for files like media spend that have dollar values.\n",
    "                # This is more robust than clean_numeric for these specific files.\n",
    "                for col in value_vars: df[col] = df[col].apply(clean_currency)\n",
    "\n",
    "                df = df.melt(id_vars=id_vars, value_vars=value_vars, var_name='month', value_name='value')\n",
    "                \n",
    "                month_map = {name: i+1 for i, name in enumerate(month_cols)}\n",
    "                df['month_num'] = df['month'].str.lower().map(month_map)\n",
    "                df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
    "                df.dropna(subset=['year', 'month_num'], inplace=True)\n",
    "                df['year'] = df['year'].astype(int)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month_num'].astype(str) + '-01', errors='coerce')\n",
    "                df.drop(columns=['year', 'month', 'month_num'], inplace=True, errors='ignore')\n",
    "\n",
    "            cleaned_dataframes[original_file_name] = df\n",
    "            print(f\"✅ Success.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            errors[original_file_name] = str(e)\n",
    "            print(f\"❌ Error: {e}\")\n",
    "\n",
    "    print(\"\\n\\n--- Processing Summary ---\")\n",
    "    if cleaned_dataframes:\n",
    "        print(f\"Successfully processed: {len(cleaned_dataframes)} files\")\n",
    "        for f in cleaned_dataframes.keys():\n",
    "            cleaned_file_name = f\"cleaned_{f}\"\n",
    "            cleaned_dataframes[f].to_csv(cleaned_file_name, index=False)\n",
    "            print(f\"  - {f} -> Saved to {cleaned_file_name}\")\n",
    "\n",
    "    if errors:\n",
    "        print(f\"\\nFailed to process: {len(errors)} files\")\n",
    "        for f, reason in errors.items():\n",
    "            print(f\"  - {f}: {reason}\")\n",
    "    \n",
    "    return cleaned_dataframes, errors\n",
    "\n",
    "# --- Run the entire cleaning process ---\n",
    "if __name__ == '__main__':\n",
    "    cleaned_data, error_log = clean_all_data_files_final()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ac11d80d-28ca-4825-9a1b-372d2e0244c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Processing: topsheet.xlsx ---\n",
      "❌ An error occurred during processing: line contains NUL\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "def clean_topsheet_file(file_path=\"topsheet.xlsx\"):\n",
    "    \"\"\"\n",
    "    Loads, cleans, and reshapes the complex TOPSHEET CSV file,\n",
    "    handling potential encoding and structural errors by parsing manually.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"--- Processing: {file_path} ---\")\n",
    "        \n",
    "        # --- Manual Parsing to fix Tokenizing Error ---\n",
    "        # This approach reads the file line-by-line to handle structural errors.\n",
    "        data = []\n",
    "        with open(file_path, 'r', encoding='latin1') as f:\n",
    "            # Use the csv reader for more robust handling of fields\n",
    "            reader = csv.reader(f)\n",
    "            for row in reader:\n",
    "                data.append(row)\n",
    "        \n",
    "        # Assume the first row is the header\n",
    "        header = data[0]\n",
    "        # Get the rest of the data\n",
    "        rows = data[1:]\n",
    "        \n",
    "        # Create the DataFrame\n",
    "        df = pd.DataFrame(rows, columns=header)\n",
    "        print(\"✅ File manually parsed successfully.\")\n",
    "\n",
    "        # --- Data Cleaning and Reshaping ---\n",
    "        \n",
    "        # 1. Standardize column names\n",
    "        df.columns = [str(col).lower().replace(' ', '_').replace('-', '_') for col in df.columns]\n",
    "        df.rename(columns={'kpi': 'metric', 'data_source': 'source'}, inplace=True)\n",
    "\n",
    "        # 2. Unpivot (melt) the data\n",
    "        month_cols = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']\n",
    "        id_vars = ['source', 'metric', 'year']\n",
    "        value_vars = [col for col in month_cols if col in df.columns]\n",
    "        \n",
    "        df_melted = df.melt(id_vars=id_vars, value_vars=value_vars, var_name='month', value_name='value')\n",
    "        print(\"✅ Data successfully unpivoted.\")\n",
    "\n",
    "        # 3. Clean the 'value' column\n",
    "        def clean_mixed_values(s):\n",
    "            if not isinstance(s, str):\n",
    "                return pd.to_numeric(s, errors='coerce')\n",
    "            s = s.replace('\\xa0', '').strip()\n",
    "            if s.lower() in ['#ref!', 'nan', '']:\n",
    "                return np.nan\n",
    "            if '%' in s:\n",
    "                return pd.to_numeric(s.replace('%', ''), errors='coerce') / 100.0\n",
    "            s = s.replace('$', '').replace(',', '')\n",
    "            if '(' in s and ')' in s:\n",
    "                s = '-' + s.replace('(', '').replace(')', '')\n",
    "            return pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "        df_melted['value'] = df_melted['value'].apply(clean_mixed_values)\n",
    "        print(\"✅ Values cleaned (currency, percentages, errors handled).\")\n",
    "\n",
    "        # 4. Create a standardized 'date' column\n",
    "        month_map = {name: i+1 for i, name in enumerate(month_cols)}\n",
    "        df_melted['month_num'] = df_melted['month'].str.lower().map(month_map)\n",
    "        df_melted['year'] = pd.to_numeric(df_melted['year'], errors='coerce')\n",
    "        \n",
    "        df_melted.dropna(subset=['year', 'month_num', 'value'], inplace=True)\n",
    "        \n",
    "        df_melted['year'] = df_melted['year'].astype(int)\n",
    "        df_melted['date'] = pd.to_datetime(df_melted['year'].astype(str) + '-' + df_melted['month_num'].astype(str) + '-01', errors='coerce')\n",
    "        \n",
    "        # 5. Finalize the DataFrame\n",
    "        final_df = df_melted[['date', 'source', 'metric', 'value']].copy()\n",
    "        final_df = final_df.sort_values(by=['metric', 'date']).reset_index(drop=True)\n",
    "        print(\"✅ Date column created and DataFrame finalized.\")\n",
    "\n",
    "        # --- Verification and Save ---\n",
    "        print(\"\\n--- Cleaning Complete ---\")\n",
    "        print(\"Here is a preview of the cleaned TOPSHEET data:\")\n",
    "        print(final_df.head())\n",
    "        \n",
    "        print(\"\\nData Types of Cleaned Columns:\")\n",
    "        final_df.info()\n",
    "\n",
    "        cleaned_file_name = \"cleaned_TOPSHEET.csv\"\n",
    "        final_df.to_csv(cleaned_file_name, index=False)\n",
    "        \n",
    "        print(f\"\\n✅ Success! The file has been cleaned and saved as '{cleaned_file_name}'.\")\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ ERROR: The file was not found at '{file_path}'.\")\n",
    "        print(\"Please make sure the file is in the same directory as your notebook.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ An error occurred during processing: {e}\")\n",
    "\n",
    "# --- Run the cleaning script ---\n",
    "if __name__ == '__main__':\n",
    "    clean_topsheet_file()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc2c1ab-582f-4654-b861-87ee5fb800de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DTC Analytics)",
   "language": "python",
   "name": "dtc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
