{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62c158c3-8fde-4b27-aa7c-23521e98f70e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading data from 'final_unified_dataset.csv' ---\n",
      "File loaded successfully.\n",
      "\n",
      "--- Correcting data redundancy ---\n",
      "Created clean business-level summary.\n",
      "Created channel-level performance summary.\n",
      "Merged data back into a non-redundant structure.\n",
      "\n",
      "--- Verification and Saving ---\n",
      "\n",
      "--- Corrected Data (First 10 Rows) ---\n",
      "   YEAR    MONTH         CHANNEL  Spend  Orders_Existing  Customers_Existing  Orders_New  Customers_New  Total_Returns  Total_Revenue\n",
      "0  2024  JANUARY       Affiliate    0.0            116.0                 0.0         0.0            0.0       -61116.9     1397391.57\n",
      "1  2024  JANUARY          Direct    0.0            793.0                 0.0       800.0            0.0       -61116.9     1397391.57\n",
      "2  2024  JANUARY         Display    0.0              0.0                58.0         0.0           24.0       -61116.9     1397391.57\n",
      "3  2024  JANUARY           Email    0.0           1158.0                 0.0       271.0            0.0       -61116.9     1397391.57\n",
      "4  2024  JANUARY  Organic Search    0.0            382.0                 0.0       682.0            0.0       -61116.9     1397391.57\n",
      "5  2024  JANUARY  Organic Social    0.0             13.0                 0.0        31.0            0.0       -61116.9     1397391.57\n",
      "6  2024  JANUARY           Other    0.0            769.0                 0.0       801.0            0.0       -61116.9     1397391.57\n",
      "7  2024  JANUARY     Paid Search    0.0           1041.0                 0.0         0.0            0.0       -61116.9     1397391.57\n",
      "8  2024  JANUARY     Paid Social    0.0            282.0                 0.0         0.0            0.0       -61116.9     1397391.57\n",
      "9  2024  JANUARY             SMS    0.0            218.0                 0.0        68.0            0.0       -61116.9     1397391.57\n",
      "\n",
      "SUCCESS: The corrected data has been saved to 'final_corrected_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Load the dataset with the redundancy issue ---\n",
    "# This is the file you provided, which we will now correct.\n",
    "source_file = 'final_unified_dataset.csv'\n",
    "\n",
    "print(f\"--- Loading data from '{source_file}' ---\")\n",
    "try:\n",
    "    df = pd.read_csv(source_file)\n",
    "    print(\"File loaded successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: The file '{source_file}' was not found.\")\n",
    "    print(\"Please make sure the CSV file is in the same directory as your notebook.\")\n",
    "    # Exit gracefully if the file isn't found\n",
    "    exit()\n",
    "\n",
    "# --- 2. Correct the Redundancy ---\n",
    "# The key to solving this is to separate business-level metrics from channel-level metrics.\n",
    "\n",
    "print(\"\\n--- Correcting data redundancy ---\")\n",
    "\n",
    "# Define which columns are at the business level (repeated for each channel in a month)\n",
    "business_level_cols = ['YEAR', 'MONTH', 'Total_Returns', 'Total_Revenue']\n",
    "\n",
    "# Define which columns are at the channel level\n",
    "channel_level_cols = ['YEAR', 'MONTH', 'CHANNEL', 'Spend', 'Orders_Existing', \n",
    "                      'Customers_Existing', 'Orders_New', 'Customers_New']\n",
    "\n",
    "# Create a clean dataframe for business-level metrics by dropping duplicates.\n",
    "# This leaves us with one unique row per month for these metrics.\n",
    "business_df = df[business_level_cols].drop_duplicates()\n",
    "print(\"Created clean business-level summary.\")\n",
    "\n",
    "# Create a dataframe for the channel-specific metrics.\n",
    "channel_df = df[channel_level_cols]\n",
    "print(\"Created channel-level performance summary.\")\n",
    "\n",
    "# Merge the two dataframes back together.\n",
    "# Pandas will correctly broadcast the single monthly business value across all the channel rows for that month.\n",
    "# This produces a clean, non-redundant, and analytically sound final table.\n",
    "final_corrected_df = pd.merge(channel_df, business_df, on=['YEAR', 'MONTH'], how='left')\n",
    "print(\"Merged data back into a non-redundant structure.\")\n",
    "\n",
    "# --- 3. Final Verification and Saving ---\n",
    "print(\"\\n--- Verification and Saving ---\")\n",
    "\n",
    "# Fill any potential NaN values that might have been created during the merge\n",
    "final_corrected_df.fillna(0, inplace=True)\n",
    "\n",
    "# Display the first 10 rows of the corrected data to verify\n",
    "print(\"\\n--- Corrected Data (First 10 Rows) ---\")\n",
    "print(final_corrected_df.head(10).to_string())\n",
    "\n",
    "# Save the final, corrected file\n",
    "output_filename = 'final_corrected_dataset.csv'\n",
    "final_corrected_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"\\nSUCCESS: The corrected data has been saved to '{output_filename}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1596ffc9-3969-4e80-9797-4d2d4773d823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading your preprocessed data from 'new.csv' ---\n",
      "File loaded successfully.\n",
      "Successfully extracted 'year' and 'month' columns.\n",
      "Standardized columns found: ['month', 'channel', 'ad_spend', 'gross_discount_shopify', 'sessions_mkt', 'ctr_mkt', 'clicks_mkt', 'conversion_rate_mkt', 'orders_mkt', 'new_customers_mkt', 'sessions_web', 'sessions_with_cart_additions', 'added_to_cart_rate', 'sessions_that_reached_checkout', 'reached_checkout_rate', 'sessions_that_completed_checkout', 'checkout_conversion_rate', 'conversion_rate_web', 'pageviews_per_session', 'pageviews', 'new_orders', 'existing_orders', 'new_customers', 'existing_customers', 'media_spend_by_channel', 'gross_sales', 'discounts', 'returns', 'net_sales', 'datetime', 'year']\n",
      "\n",
      "--- Correcting data redundancy ---\n",
      "Created clean business-level summary.\n",
      "Created channel-level performance summary.\n",
      "Merged data back into a non-redundant structure.\n",
      "\n",
      "--- Verification and Saving ---\n",
      "\n",
      "--- Final Corrected Data (First 10 Rows) ---\n",
      "   year      month      channel    ad_spend  gross_discount_shopify  sessions_mkt  ctr_mkt  clicks_mkt  conversion_rate_mkt  orders_mkt  new_customers_mkt  sessions_web  sessions_with_cart_additions  added_to_cart_rate  sessions_that_reached_checkout  reached_checkout_rate  sessions_that_completed_checkout  checkout_conversion_rate  conversion_rate_web  pageviews_per_session  pageviews  new_orders  existing_orders  new_customers  existing_customers  media_spend_by_channel  discounts   returns  gross_sales   net_sales\n",
      "0  2024    JANUARY  paid social  1708185.25              1354900.53      733202.0   0.0119   1039302.0               0.0199     14620.0             7907.0      342385.0                       11370.0                0.03                         10522.0                   0.03                            5897.0                      0.56                 0.02                   2.47   844908.0      1100.0            800.0         1066.0               534.0                 48252.0 -107428.31 -61116.90   1047386.58   878841.37\n",
      "1  2024   FEBRUARY  paid social  1708185.25              1354900.53      733202.0   0.0119   1039302.0               0.0199     14620.0             7907.0      345773.0                       16583.0                0.05                         12264.0                   0.04                            7568.0                      0.62                 0.02                   3.05  1054390.0      1080.0            780.0         1044.0               520.0                 99304.0 -103694.61 -46543.44   1050134.33   899896.28\n",
      "2  2024      MARCH  paid social  1708185.25              1354900.53      733202.0   0.0119   1039302.0               0.0199     14620.0             7907.0      286656.0                       18153.0                0.06                         13083.0                   0.05                            8476.0                      0.65                 0.03                   3.27   936210.0       830.0            600.0          815.0               400.0                 79542.0  -87628.99 -50138.12   1042431.81   904664.70\n",
      "3  2024      APRIL  paid social  1708185.25              1354900.53      733202.0   0.0119   1039302.0               0.0199     14620.0             7907.0      300478.0                       21545.0                0.07                         15317.0                   0.05                            9018.0                      0.59                 0.03                   3.48  1046813.0       850.0            620.0          833.0               410.0                 95402.0 -182409.52 -42238.03   1254339.50  1029691.95\n",
      "4  2024        MAY  paid social  1708185.25              1354900.53      733202.0   0.0119   1039302.0               0.0199     14620.0             7907.0      403487.0                       32837.0                0.08                         22473.0                   0.06                           14535.0                      0.65                 0.04                   3.61  1454783.0       600.0           3500.0          588.0              2352.0                203679.0 -296241.55 -53802.15   1794135.77  1444092.07\n",
      "5  2024       JUNE  paid social  1708185.25              1354900.53      733202.0   0.0119   1039302.0               0.0199     14620.0             7907.0      375783.0                       20096.0                0.05                         14189.0                   0.04                            8790.0                      0.62                 0.02                   2.84  1068859.0       620.0           3600.0          600.0              2400.0                 85372.0 -109422.36 -51017.60   1102399.45   941959.49\n",
      "6  2024       JULY  paid social  1708185.25              1354900.53      733202.0   0.0119   1039302.0               0.0199     14620.0             7907.0      396521.0                       19410.0                0.05                         13620.0                   0.03                            8228.0                      0.60                 0.02                   2.83  1120936.0       210.0           1250.0          208.0               832.0                 97484.0  -88930.89 -46815.46   1017758.01   882011.66\n",
      "7  2024     AUGUST  paid social  1708185.25              1354900.53      733202.0   0.0119   1039302.0               0.0199     14620.0             7907.0      418982.0                       22379.0                0.05                         16020.0                   0.04                            9813.0                      0.61                 0.02                   2.82  1179673.0       220.0           1280.0          212.0               850.0                112965.0  -94359.42 -35156.10   1203508.98  1073993.46\n",
      "8  2024  SEPTEMBER  paid social  1708185.25              1354900.53      733202.0   0.0119   1039302.0               0.0199     14620.0             7907.0      361476.0                       19866.0                0.05                         13276.0                   0.04                            8342.0                      0.63                 0.02                   2.79  1008213.0      1250.0            900.0         1222.0               610.0                134002.0  -99623.56 -35440.03   1037038.97   901975.38\n",
      "9  2024    OCTOBER  paid social  1708185.25              1354900.53      733202.0   0.0119   1039302.0               0.0199     14620.0             7907.0      304644.0                       26404.0                0.09                         14884.0                   0.05                            8104.0                      0.54                 0.03                   3.21   977883.0      1080.0            780.0         1050.0               525.0                130267.0 -176537.57 -32516.32   1146811.38   937757.49\n",
      "\n",
      "SUCCESS: The definitive, non-redundant data has been saved to 'final_master_dataset.csv'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Load your manually preprocessed dataset ---\n",
    "# This script uses your 'new.csv' as the starting point.\n",
    "source_file = 'new.csv'\n",
    "\n",
    "print(f\"--- Loading your preprocessed data from '{source_file}' ---\")\n",
    "try:\n",
    "    # Load the data, assuming the first row is the header\n",
    "    df = pd.read_csv(source_file, encoding='latin-1', header=0)\n",
    "    \n",
    "    # Standardize all column names to prevent KeyErrors\n",
    "    # Convert to lowercase, replace spaces and special characters with underscores\n",
    "    df.columns = df.columns.str.lower().str.replace(r'[^a-zA-Z0-9_]', '_', regex=True)\n",
    "    \n",
    "    print(\"File loaded successfully.\")\n",
    "    \n",
    "    # --- FIX: Extract YEAR and MONTH from the date column ---\n",
    "    # Intelligently find the date column\n",
    "    date_col = next((col for col in df.columns if 'month' in col or 'date' in col), None)\n",
    "    if date_col:\n",
    "        df['datetime'] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "        df['year'] = df['datetime'].dt.year\n",
    "        df['month'] = df['datetime'].dt.month_name().str.upper()\n",
    "        # Drop rows where date conversion failed\n",
    "        df.dropna(subset=['datetime'], inplace=True)\n",
    "        print(\"Successfully extracted 'year' and 'month' columns.\")\n",
    "    else:\n",
    "        raise ValueError(\"Could not find a date-like column (e.g., 'month' or 'date') in the CSV.\")\n",
    "\n",
    "    print(\"Standardized columns found:\", df.columns.tolist())\n",
    "    \n",
    "except (FileNotFoundError, ValueError) as e:\n",
    "    print(f\"ERROR: {e}\")\n",
    "    # Exit gracefully if there's an issue\n",
    "    exit()\n",
    "\n",
    "# --- 2. Correct the Redundancy ---\n",
    "# This is the final and most critical step to ensure the data is analytically sound.\n",
    "\n",
    "print(\"\\n--- Correcting data redundancy ---\")\n",
    "\n",
    "# Define which columns are at the business level (repeated for each channel in a month)\n",
    "business_level_cols = ['year', 'month', 'returns', 'gross_sales', 'net_sales']\n",
    "# Ensure we only use columns that actually exist in the dataframe\n",
    "business_level_cols = [col for col in business_level_cols if col in df.columns]\n",
    "\n",
    "\n",
    "# Define which columns are at the channel level\n",
    "channel_level_cols = [col for col in df.columns if col not in business_level_cols]\n",
    "# Add back the keys needed for merging\n",
    "channel_level_cols = ['year', 'month', 'channel'] + [col for col in channel_level_cols if col not in ['year', 'month', 'channel', 'datetime']]\n",
    "\n",
    "\n",
    "# Create a clean dataframe for business-level metrics by dropping duplicates.\n",
    "business_df = df[business_level_cols].drop_duplicates()\n",
    "print(\"Created clean business-level summary.\")\n",
    "\n",
    "# Create a dataframe for the channel-specific metrics.\n",
    "channel_df = df[channel_level_cols]\n",
    "print(\"Created channel-level performance summary.\")\n",
    "\n",
    "# Merge the two dataframes back together.\n",
    "final_corrected_df = pd.merge(channel_df, business_df, on=['year', 'month'], how='left')\n",
    "print(\"Merged data back into a non-redundant structure.\")\n",
    "\n",
    "# --- 3. Final Verification and Saving ---\n",
    "print(\"\\n--- Verification and Saving ---\")\n",
    "\n",
    "# Fill any potential NaN values that might have been created during the merge\n",
    "final_corrected_df.fillna(0, inplace=True)\n",
    "\n",
    "# Remove any summary rows like 'TOTAL' that might exist\n",
    "if 'channel' in final_corrected_df.columns:\n",
    "    final_corrected_df = final_corrected_df[~final_corrected_df['channel'].str.contains('TOTAL', na=False, case=False)]\n",
    "\n",
    "\n",
    "# Display the first 10 rows of the corrected data to verify\n",
    "print(\"\\n--- Final Corrected Data (First 10 Rows) ---\")\n",
    "print(final_corrected_df.head(10).to_string())\n",
    "\n",
    "# Save the final, corrected file\n",
    "output_filename = 'final_master_dataset.csv'\n",
    "final_corrected_df.to_csv(output_filename, index=False)\n",
    "\n",
    "print(f\"\\nSUCCESS: The definitive, non-redundant data has been saved to '{output_filename}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d19f5f9-551e-4ded-aac1-32d2dc0f6e6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DTC Analytics)",
   "language": "python",
   "name": "dtc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
