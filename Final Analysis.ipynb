{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase 2: Advanced Model Training & Evaluation\n",
    "\n",
    "This notebook serves as the primary script for training and evaluating predictive models (e.g., churn, LTV). It incorporates the accuracy upgrades specified in the project brief, including robust data validation, imputation, and time-aware cross-validation.\n",
    "\n",
    "**Workflow:**\n",
    "1.  Run `data_preparation_pipeline.py` first to generate the analysis-ready data.\n",
    "2.  This notebook loads the final, clean data from `/data/analysis_ready/`.\n",
    "3.  It then trains a model using the best hyperparameters found via Optuna and evaluates it with `TimeSeriesSplit`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import logging\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Analysis-Ready Data\n",
    "\n",
    "Load the clean, validated, and imputed data generated by the preparation pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 22:24:14,041 - INFO - Successfully loaded analysis-ready data.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  mapping_key  total_spend   net_revenue  imputed_bool  \\\n",
      "11 2022-01-01    affiliate      68418.0  46565.416276          True   \n",
      "3  2022-01-01  paid search      51972.0  44426.868685          True   \n",
      "7  2022-01-01  paid social      17057.0  39886.713684          True   \n",
      "19 2022-02-01  paid social       6602.0  38527.202857          True   \n",
      "15 2022-02-01  paid search      35202.0  42246.189912          True   \n",
      "\n",
      "    monthly_roas  monthly_cac  \n",
      "11      0.680602    74.267960  \n",
      "3       0.854823    62.768116  \n",
      "7       2.338437    55.022581  \n",
      "19      5.835687    25.688716  \n",
      "15      1.200108    43.298893  \n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Load the final trends data\n",
    "    df = pd.read_csv('data/analysis_ready/final_monthly_trends.csv')\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    df.sort_values('date', inplace=True)\n",
    "    \n",
    "    logging.info(\"Successfully loaded analysis-ready data.\")\n",
    "    print(df.head())\n",
    "except FileNotFoundError:\n",
    "    logging.error(\"Error: 'final_monthly_trends.csv' not found. Please run data_preparation_pipeline.py first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering & Model Preparation\n",
    "\n",
    "Prepare the features (X) and target variable (y) for the churn model. For this demonstration, we will create a synthetic `churned` column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 22:24:29,949 - INFO - Features for modeling: ['total_spend', 'net_revenue', 'monthly_roas', 'monthly_cac']\n"
     ]
    }
   ],
   "source": [
    "# Create a sample target variable for demonstration (e.g., churn prediction)\n",
    "# In a real scenario, this would be based on actual customer behavior.\n",
    "df['churned'] = (df['monthly_roas'] < 1.5).astype(int)\n",
    "\n",
    "# Define features and target\n",
    "features = ['total_spend', 'net_revenue', 'monthly_roas', 'monthly_cac']\n",
    "target = 'churned'\n",
    "\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "logging.info(f\"Features for modeling: {features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train Model with Best Hyperparameters and TimeSeriesSplit\n",
    "\n",
    "This section implements Task 8.3 and 8.4. It uses the optimal parameters found by the Optuna script and evaluates the model using a robust time-series cross-validation strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 22:24:47,057 - INFO - Using best hyperparameters found by Optuna.\n",
      "2025-07-01 22:24:47,066 - INFO - Performing cross-validation with TimeSeriesSplit (n_splits=5)...\n",
      "2025-07-01 22:24:47,338 - INFO - Fold 1: Train size=23, Test size=20, AUC=1.0000\n",
      "2025-07-01 22:24:47,467 - INFO - Fold 2: Train size=43, Test size=20, AUC=1.0000\n",
      "2025-07-01 22:24:47,600 - INFO - Fold 3: Train size=63, Test size=20, AUC=0.2798\n",
      "2025-07-01 22:24:47,732 - INFO - Fold 4: Train size=83, Test size=20, AUC=1.0000\n",
      "2025-07-01 22:24:47,881 - INFO - Fold 5: Train size=103, Test size=20, AUC=1.0000\n",
      "2025-07-01 22:24:47,881 - INFO - \n",
      "Final Mean Cross-Validated AUC: 0.8560\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model training and evaluation complete.\n",
      "The average AUC score using the optimized model is: 0.8560\n"
     ]
    }
   ],
   "source": [
    "# Best parameters found from the hyperparameter_tuning.py script (Task 8.4)\n",
    "best_params = {\n",
    "    'n_estimators': 184,\n",
    "    'max_depth': 6,\n",
    "    'learning_rate': 0.1842290290462422,\n",
    "    'subsample': 0.7885720186693017,\n",
    "    'colsample_bytree': 0.8096297971911706,\n",
    "    'gamma': 3.8149755795467173,\n",
    "    'objective': 'binary:logistic',\n",
    "    'eval_metric': 'auc',\n",
    "    'random_state': 42\n",
    "}\n",
    "\n",
    "logging.info(\"Using best hyperparameters found by Optuna.\")\n",
    "\n",
    "# Initialize the model with the best parameters\n",
    "model = xgb.XGBClassifier(**best_params)\n",
    "\n",
    "# Use TimeSeriesSplit for cross-validation (Task 8.3)\n",
    "n_splits = 5\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
    "\n",
    "logging.info(f\"Performing cross-validation with TimeSeriesSplit (n_splits={n_splits})...\")\n",
    "\n",
    "auc_scores = []\n",
    "fold = 1\n",
    "for train_index, test_index in tscv.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # Predict probabilities for the positive class\n",
    "    y_pred_proba = model.predict_proba(X_test)[:, 1]\n",
    "    \n",
    "    auc = roc_auc_score(y_test, y_pred_proba)\n",
    "    auc_scores.append(auc)\n",
    "    logging.info(f\"Fold {fold}: Train size={len(X_train)}, Test size={len(X_test)}, AUC={auc:.4f}\")\n",
    "    fold += 1\n",
    "\n",
    "mean_auc = np.mean(auc_scores)\n",
    "logging.info(f\"\\nFinal Mean Cross-Validated AUC: {mean_auc:.4f}\")\n",
    "\n",
    "print(f\"\\nModel training and evaluation complete.\")\n",
    "print(f\"The average AUC score using the optimized model is: {mean_auc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DTC Analytics)",
   "language": "python",
   "name": "dtc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
