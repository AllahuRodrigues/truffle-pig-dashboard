{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ExcelDemocracy: Conversion Prediction Model\n",
    "\n",
    "**Project:** Proof-of-Concept for Truffle Pig\n",
    "**Objective:** Train an XGBoost classifier to predict the likelihood of a user session converting into an order. The model's performance will be used to power a 'Lift Forecast' feature in the final Streamlit dashboard.\n",
    "\n",
    "**Methodology:**\n",
    "1.  **Load & Merge Data:** Load the `sessions.csv`, `campaigns.csv`, and `orders.csv` files.\n",
    "2.  **Feature Engineering:** Create new features from the raw data to improve model performance.\n",
    "3.  **Data Splitting:** Split the data chronologically into three sets: 70% for training, 15% for hyperparameter tuning, and 15% for final testing.\n",
    "4.  **Hyperparameter Tuning:** Use Optuna to find the best hyperparameters for the XGBoost model on the tuning set.\n",
    "5.  **Final Evaluation:** Train the model with the best parameters on the full training set and evaluate its performance on the unseen test set, targeting an AUC-ROC score of â‰¥ 0.85.\n",
    "6.  **Save Artifacts:** Save the trained model and feature list for use in the Streamlit dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"Libraries imported successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the mock data files\n",
    "sessions_df = pd.read_csv('sessions.csv')\n",
    "campaigns_df = pd.read_csv('campaigns.csv')\n",
    "orders_df = pd.read_csv('orders.csv') # Load orders for context, not features\n",
    "\n",
    "# Convert date columns to datetime objects\n",
    "sessions_df['session_start'] = pd.to_datetime(sessions_df['session_start'])\n",
    "campaigns_df['start_date'] = pd.to_datetime(campaigns_df['start_date'])\n",
    "\n",
    "# Merge sessions with campaign data\n",
    "data_df = pd.merge(sessions_df, campaigns_df, on='campaign_id', how='left')\n",
    "\n",
    "print(\"Data loaded and merged successfully.\")\n",
    "print(f\"Total records: {len(data_df)}\")\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "\n",
    "Create new features to help the model learn patterns. This includes time-based features and one-hot encoding for categorical variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based features\n",
    "data_df['hour_of_day'] = data_df['session_start'].dt.hour\n",
    "data_df['day_of_week'] = data_df['session_start'].dt.dayofweek # Monday=0, Sunday=6\n",
    "data_df['month'] = data_df['session_start'].dt.month\n",
    "\n",
    "# One-hot encode categorical features\n",
    "categorical_cols = ['utm_source', 'utm_medium', 'creative_format', 'creative_theme', 'effectiveness_tier']\n",
    "data_df = pd.get_dummies(data_df, columns=categorical_cols, dummy_na=True)\n",
    "\n",
    "# Fill NaN values for spend (for sessions with no campaign)\n",
    "data_df['spend'] = data_df['spend'].fillna(0)\n",
    "\n",
    "print(\"Feature engineering complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Splitting (70/15/15)\n",
    "\n",
    "Split the data chronologically to prevent data leakage. The first 70% of the data will be for training, the next 15% for tuning, and the final 15% for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort data by time to ensure a proper chronological split\n",
    "data_df.sort_values('session_start', inplace=True)\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "target = 'converted'\n",
    "# We exclude identifiers, dates, and the target itself.\n",
    "# 'spend' IS included as a feature.\n",
    "features_to_exclude = ['session_id', 'user_id', 'session_start', 'campaign_id', 'campaign_name', 'start_date', 'target']\n",
    "features = [col for col in data_df.columns if col not in features_to_exclude and col != target]\n",
    "\n",
    "X = data_df[features]\n",
    "y = data_df[target]\n",
    "\n",
    "# Calculate split points\n",
    "train_size = int(0.7 * len(data_df))\n",
    "tune_size = int(0.15 * len(data_df))\n",
    "\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_tune, y_tune = X[train_size:train_size + tune_size], y[train_size:train_size + tune_size]\n",
    "X_test, y_test = X[train_size + tune_size:], y[train_size + tune_size:]\n",
    "\n",
    "print(f\"Train set size: {len(X_train)}\")\n",
    "print(f\"Tune set size:  {len(X_tune)}\")\n",
    "print(f\"Test set size:  {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hyperparameter Tuning with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \"\"\"Objective function for Optuna to maximize AUC-ROC.\"\"\"\n",
    "    params = {\n",
    "        'objective': 'binary:logistic',\n",
    "        'eval_metric': 'auc',\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 200, 1000),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.6, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.6, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0.0, 5.0)\n",
    "    }\n",
    "    \n",
    "    model = xgb.XGBClassifier(**params, use_label_encoder=False)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_tune, y_tune)], verbose=False, early_stopping_rounds=50)\n",
    "    \n",
    "    preds = model.predict_proba(X_tune)[:, 1]\n",
    "    auc = roc_auc_score(y_tune, preds)\n",
    "    return auc\n",
    "\n",
    "print(\"Starting hyperparameter tuning with Optuna...\")\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=25) # Run 25 trials for speed\n",
    "\n",
    "print(\"Tuning complete!\")\n",
    "print(f\"Best AUC on tune set: {study.best_value:.4f}\")\n",
    "print(\"Best parameters found:\")\n",
    "best_params = study.best_params\n",
    "print(best_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Final Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the final model on the full training data using the best parameters\n",
    "final_model = xgb.XGBClassifier(**best_params, use_label_encoder=False)\n",
    "\n",
    "# Combine train and tune sets for final training\n",
    "X_train_full = pd.concat([X_train, X_tune])\n",
    "y_train_full = pd.concat([y_train, y_tune])\n",
    "\n",
    "final_model.fit(X_train_full, y_train_full, verbose=False)\n",
    "\n",
    "# Evaluate on the unseen test set\n",
    "test_preds = final_model.predict_proba(X_test)[:, 1]\n",
    "test_auc = roc_auc_score(y_test, test_preds)\n",
    "\n",
    "print(f\"\\n--- Final Model Performance ---\")\n",
    "print(f\"AUC-ROC on Test Set: {test_auc:.4f}\")\n",
    "\n",
    "# Plot ROC Curve\n",
    "fpr, tpr, _ = roc_curve(y_test, test_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {test_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance\n",
    "\n",
    "This chart shows which factors the model considered most important when predicting conversions. This helps answer the client's question of *how* we are winning or losing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame({\n",
    "    'feature': features,\n",
    "    'importance': final_model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(x='importance', y='feature', data=feature_importances.head(15))\n",
    "plt.title('Top 15 Feature Importances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Save Model and Features\n",
    "\n",
    "Save the trained model and the list of features it was trained on. The Streamlit dashboard will load these files directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path(\"conversion_model.joblib\")\n",
    "features_path = Path(\"model_features.joblib\")\n",
    "\n",
    "joblib.dump(final_model, model_path)\n",
    "joblib.dump(features, features_path)\n",
    "\n",
    "print(f\"âœ… Model saved to: {model_path}\")\n",
    "print(f\"âœ… Features list saved to: {features_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
