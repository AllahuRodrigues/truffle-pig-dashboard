{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23296ff0-ec51-41bf-9783-0a681e4270d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10 files to process...\n",
      "--- Processing: Cust By Channel-Ext.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Cust By Channel-New.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Email.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Marketing Channel Breakdown.csv ---\n",
      "❌ Error: \"The following id_vars or value_vars are not present in the DataFrame: ['channel_name', 'year']\"\n",
      "--- Processing: Media Spend by Channel.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Orders By Channel-Ext.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Orders By Channel-New.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Returns.csv ---\n",
      "✅ Success.\n",
      "--- Processing: TOPSHEET.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Web Analytics.csv ---\n",
      "✅ Success.\n",
      "\n",
      "\n",
      "--- Processing Summary ---\n",
      "Successfully processed: 9 files\n",
      "  - Cust By Channel-Ext.csv -> Saved to cleaned_Cust By Channel-Ext.csv\n",
      "  - Cust By Channel-New.csv -> Saved to cleaned_Cust By Channel-New.csv\n",
      "  - Email.csv -> Saved to cleaned_Email.csv\n",
      "  - Media Spend by Channel.csv -> Saved to cleaned_Media Spend by Channel.csv\n",
      "  - Orders By Channel-Ext.csv -> Saved to cleaned_Orders By Channel-Ext.csv\n",
      "  - Orders By Channel-New.csv -> Saved to cleaned_Orders By Channel-New.csv\n",
      "  - Returns.csv -> Saved to cleaned_Returns.csv\n",
      "  - TOPSHEET.csv -> Saved to cleaned_TOPSHEET.csv\n",
      "  - Web Analytics.csv -> Saved to cleaned_Web Analytics.csv\n",
      "\n",
      "Failed to process: 1 files\n",
      "  - Marketing Channel Breakdown.csv: \"The following id_vars or value_vars are not present in the DataFrame: ['channel_name', 'year']\"\n",
      "\n",
      "--- Sample of Cleaned Data (Media Spend by Channel.csv) ---\n",
      "        channel_name   value       date\n",
      "0  Paid Search Media   52392 2025-01-01\n",
      "1  Paid Search Media   33131 2024-01-01\n",
      "2  Paid Search Media   46139 2023-01-01\n",
      "3  Paid Search Media   51972 2022-01-01\n",
      "4  Paid Social Media  110665 2025-01-01\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "def clean_and_process_all_files():\n",
    "    \"\"\"\n",
    "    Finds all relevant CSVs in the folder, then loads, cleans, and processes them.\n",
    "    - Cleans currency and percentage strings.\n",
    "    - Reshapes wide-format data to long format.\n",
    "    - Standardizes column names.\n",
    "    - Handles file not found errors gracefully.\n",
    "    - Saves cleaned files to new CSVs.\n",
    "    \"\"\"\n",
    "    # Use glob to find the files in the current directory\n",
    "    file_names = [f for f in glob.glob(\"*.csv\") if not f.startswith('cleaned_')]\n",
    "    \n",
    "    cleaned_dataframes = {}\n",
    "    errors = {}\n",
    "\n",
    "    print(f\"Found {len(file_names)} files to process...\")\n",
    "\n",
    "    # --- Helper Functions ---\n",
    "    def clean_currency(s):\n",
    "        if isinstance(s, str):\n",
    "            s = s.replace('$', '').replace(',', '')\n",
    "            if '(' in s and ')' in s:\n",
    "                s = '-' + s.replace('(', '').replace(')', '')\n",
    "            return pd.to_numeric(s, errors='coerce')\n",
    "        return s\n",
    "\n",
    "    def clean_numeric_string(s):\n",
    "        if isinstance(s, str):\n",
    "            return pd.to_numeric(s.replace(',', ''), errors='coerce')\n",
    "        return s\n",
    "\n",
    "    def clean_percentage(s):\n",
    "        if isinstance(s, str):\n",
    "            return pd.to_numeric(s.replace('%', ''), errors='coerce') / 100.0\n",
    "        return s\n",
    "\n",
    "    for file_name in file_names:\n",
    "        try:\n",
    "            print(f\"--- Processing: {file_name} ---\")\n",
    "            \n",
    "            separator = '\\t' if file_name == \"Marketing Channel Breakdown.csv\" else ','\n",
    "            df = pd.read_csv(file_name, sep=separator)\n",
    "            \n",
    "            original_file_name = file_name # Keep track of the original name\n",
    "            \n",
    "            # Standardize column names\n",
    "            df.columns = [str(col).lower().replace(' ', '_').replace('-', '_') for col in df.columns]\n",
    "\n",
    "            if 'returns' in file_name.lower():\n",
    "                for col in ['gross_sales', 'discounts', 'returns', 'net_sales']:\n",
    "                    df[col] = df[col].apply(clean_currency)\n",
    "                df['month'] = pd.to_datetime(df['month'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "            elif 'email' in file_name.lower():\n",
    "                df.rename(columns={'type_(batch_marketing,_triggered,_transactional)': 'email_type'}, inplace=True)\n",
    "                df['sends'] = df['sends'].apply(clean_numeric_string)\n",
    "                df['clicks'] = df['clicks'].apply(clean_numeric_string)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01', errors='coerce')\n",
    "                df = df[['date', 'email_type', 'sends', 'clicks']]\n",
    "            \n",
    "            elif 'web_analytics' in file_name.lower():\n",
    "                for col in ['added_to_cart_rate', 'reached_checkout_rate', 'checkout_conversion_rate', 'conversion_rate']:\n",
    "                    df[col] = df[col].apply(clean_percentage)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01', errors='coerce')\n",
    "                df.drop(columns=['year', 'month'], inplace=True, errors='ignore')\n",
    "\n",
    "            elif 'channel' in file_name.lower() or 'topsheet' in file_name.lower():\n",
    "                if 'topsheet' in file_name.lower():\n",
    "                    df.rename(columns={'kpi': 'metric', 'data_source': 'source'}, inplace=True)\n",
    "                    id_vars = ['source', 'metric', 'year']\n",
    "                else:\n",
    "                    df.rename(columns={'channel': 'channel_name'}, inplace=True)\n",
    "                    id_vars = ['channel_name', 'year']\n",
    "                \n",
    "                month_cols = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']\n",
    "                value_vars = [col for col in month_cols if col in df.columns]\n",
    "                \n",
    "                for col in value_vars:\n",
    "                    df[col] = df[col].astype(str).str.replace(',', '').str.replace('$', '').str.replace('%', '')\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "                df = df.melt(id_vars=id_vars, value_vars=value_vars, var_name='month', value_name='value')\n",
    "                \n",
    "                month_map = {name: i+1 for i, name in enumerate(month_cols)}\n",
    "                df['month_num'] = df['month'].str.lower().map(month_map)\n",
    "                df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
    "                df.dropna(subset=['year', 'month_num'], inplace=True)\n",
    "                df['year'] = df['year'].astype(int)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month_num'].astype(str) + '-01', errors='coerce')\n",
    "                df.drop(columns=['year', 'month', 'month_num'], inplace=True, errors='ignore')\n",
    "            \n",
    "            elif 'marketing_channel_breakdown' in file_name.lower():\n",
    "                 # This file might have a year as the first column, let's rename it\n",
    "                df.rename(columns={df.columns[0]: 'year'}, inplace=True)\n",
    "                # Add cleaning logic for its specific currency/numeric columns if needed\n",
    "                for col in ['ad_spend', 'gross_discount_(shopify)', 'sessions', 'clicks', 'orders', 'new_customers']:\n",
    "                    if col in df.columns:\n",
    "                        df[col] = df[col].apply(clean_numeric_string)\n",
    "                for col in ['ctr', 'conversion_rate']:\n",
    "                     if col in df.columns:\n",
    "                        df[col] = df[col].apply(clean_percentage)\n",
    "\n",
    "            cleaned_dataframes[original_file_name] = df\n",
    "            print(f\"✅ Success.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            errors[original_file_name] = str(e)\n",
    "            print(f\"❌ Error: {e}\")\n",
    "\n",
    "    print(\"\\n\\n--- Processing Summary ---\")\n",
    "    if cleaned_dataframes:\n",
    "        print(f\"Successfully processed: {len(cleaned_dataframes)} files\")\n",
    "        for f in cleaned_dataframes.keys():\n",
    "            cleaned_file_name = f\"cleaned_{f}\"\n",
    "            cleaned_dataframes[f].to_csv(cleaned_file_name, index=False)\n",
    "            print(f\"  - {f} -> Saved to {cleaned_file_name}\")\n",
    "\n",
    "    if errors:\n",
    "        print(f\"\\nFailed to process: {len(errors)} files\")\n",
    "        for f, reason in errors.items():\n",
    "            print(f\"  - {f}: {reason}\")\n",
    "    \n",
    "    return cleaned_dataframes, errors\n",
    "\n",
    "# --- Run the script ---\n",
    "if __name__ == '__main__':\n",
    "    cleaned_data, error_log = clean_and_process_all_files()\n",
    "\n",
    "    # As an example, display the first 5 rows of a cleaned, reshaped file\n",
    "    if 'Media Spend by Channel.csv' in cleaned_data:\n",
    "        print(\"\\n--- Sample of Cleaned Data (Media Spend by Channel.csv) ---\")\n",
    "        print(cleaned_data['Media Spend by Channel.csv'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "03c33f34-8953-44fd-bed7-7ad27d60455d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Analysis for cleaned_Cust By Channel-Ext.csv ---\n",
      "\n",
      "\n",
      "--- Data Types and Non-Null Counts ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 648 entries, 0 to 647\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   channel_name  648 non-null    object\n",
      " 1   value         648 non-null    int64 \n",
      " 2   date          648 non-null    object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 15.3+ KB\n",
      "\n",
      "\n",
      "--- Duplicates Check ---\n",
      "Number of duplicate rows found: 0\n",
      "\n",
      "\n",
      "--- Descriptive Statistics ---\n",
      "Could not generate full descriptive statistics. Error: NDFrame.describe() got an unexpected keyword argument 'datetime_is_numeric'\n",
      "\n",
      "\n",
      "--- Unique Channel Names ---\n",
      "['Paid Search' 'Paid Social' 'Affiliate' 'Display' 'Email' 'SMS'\n",
      " 'Organic Search' 'Direct' 'Unattributed' 'Other' 'Organic Social']\n",
      "\n",
      "\n",
      "--- Negative Value Check ---\n",
      "No negative customer counts found. That's good.\n",
      "\n",
      "\n",
      "--- Date Range Check ---\n",
      "Date range: 2021-01-01 to 2025-12-01\n",
      "MISTAKE FOUND: There are 50 dates in the future (after July 1, 2025).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    # Load the user-provided cleaned file\n",
    "    file_path = \"cleaned_Cust By Channel-Ext.csv\"\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    print(f\"--- Analysis for {file_path} ---\")\n",
    "\n",
    "    # --- 1. Check Data Types and Null Values ---\n",
    "    print(\"\\n\\n--- Data Types and Non-Null Counts ---\")\n",
    "    # Use a buffer to capture the info() output as a string\n",
    "    from io import StringIO\n",
    "    buffer = StringIO()\n",
    "    df.info(buf=buffer)\n",
    "    info_str = buffer.getvalue()\n",
    "    print(info_str)\n",
    "\n",
    "    # --- 2. Check for Duplicates ---\n",
    "    duplicate_rows = df.duplicated().sum()\n",
    "    print(f\"\\n--- Duplicates Check ---\")\n",
    "    print(f\"Number of duplicate rows found: {duplicate_rows}\")\n",
    "\n",
    "\n",
    "    # --- 3. Examine Descriptive Statistics ---\n",
    "    print(\"\\n\\n--- Descriptive Statistics ---\")\n",
    "    # The datetime_is_numeric=True is needed for newer pandas versions\n",
    "    try:\n",
    "        # Temporarily convert date for describe if it's object\n",
    "        if df['date'].dtype == 'object':\n",
    "            df['date'] = pd.to_datetime(df['date'])\n",
    "        print(df.describe(include='all', datetime_is_numeric=True))\n",
    "    except Exception as e:\n",
    "        print(f\"Could not generate full descriptive statistics. Error: {e}\")\n",
    "\n",
    "\n",
    "    # --- 4. Deep Dive into Specific Columns ---\n",
    "\n",
    "    # Channel Name consistency\n",
    "    print(\"\\n\\n--- Unique Channel Names ---\")\n",
    "    unique_channels = df['channel_name'].unique()\n",
    "    print(unique_channels)\n",
    "\n",
    "    # Check for negative values where they shouldn't be\n",
    "    print(\"\\n\\n--- Negative Value Check ---\")\n",
    "    if 'value' in df.columns and pd.api.types.is_numeric_dtype(df['value']):\n",
    "        negative_values = df[df['value'] < 0].shape[0]\n",
    "        if negative_values > 0:\n",
    "            print(f\"MISTAKE FOUND: There are {negative_values} rows with negative customer counts.\")\n",
    "        else:\n",
    "            print(\"No negative customer counts found. That's good.\")\n",
    "    else:\n",
    "        print(\"Could not perform negative value check on 'value' column.\")\n",
    "\n",
    "    # Check the date range\n",
    "    print(\"\\n\\n--- Date Range Check ---\")\n",
    "    if 'date' in df.columns:\n",
    "        try:\n",
    "            # Ensure 'date' column is datetime\n",
    "            if df['date'].dtype != '<M8[ns]':\n",
    "                 df['date'] = pd.to_datetime(df['date'])\n",
    "            \n",
    "            min_date = df['date'].min().strftime('%Y-%m-%d')\n",
    "            max_date = df['date'].max().strftime('%Y-%m-%d')\n",
    "            print(f\"Date range: {min_date} to {max_date}\")\n",
    "\n",
    "            # Check if any dates are in the future\n",
    "            # Using a fixed date for reproducibility based on conversation context\n",
    "            future_dates = df[df['date'] > pd.to_datetime(\"2025-07-01\")].shape[0]\n",
    "            if future_dates > 0:\n",
    "                 print(f\"MISTAKE FOUND: There are {future_dates} dates in the future (after July 1, 2025).\")\n",
    "            else:\n",
    "                 print(\"No future dates found. That's good.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Could not perform date analysis. Error: {e}\")\n",
    "\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: The file '{file_path}' was not found. Please ensure it's in the same directory as your notebook.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during analysis: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f6a383f-56f0-4bb3-a7b1-986726e9f6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the cleaning process for 9 files...\n",
      "--- Processing: Cust By Channel-Ext.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Cust By Channel-New.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Email.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Media Spend by Channel.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Orders By Channel-Ext.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Orders By Channel-New.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Returns.csv ---\n",
      "✅ Success.\n",
      "--- Processing: TOPSHEET.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Web Analytics.csv ---\n",
      "✅ Success.\n",
      "\n",
      "\n",
      "--- Processing Summary ---\n",
      "Successfully processed: 9 files\n",
      "  - Cust By Channel-Ext.csv -> Saved to cleaned_Cust By Channel-Ext.csv\n",
      "  - Cust By Channel-New.csv -> Saved to cleaned_Cust By Channel-New.csv\n",
      "  - Email.csv -> Saved to cleaned_Email.csv\n",
      "  - Media Spend by Channel.csv -> Saved to cleaned_Media Spend by Channel.csv\n",
      "  - Orders By Channel-Ext.csv -> Saved to cleaned_Orders By Channel-Ext.csv\n",
      "  - Orders By Channel-New.csv -> Saved to cleaned_Orders By Channel-New.csv\n",
      "  - Returns.csv -> Saved to cleaned_Returns.csv\n",
      "  - TOPSHEET.csv -> Saved to cleaned_TOPSHEET.csv\n",
      "  - Web Analytics.csv -> Saved to cleaned_Web Analytics.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "\n",
    "def clean_all_data_files_final():\n",
    "    \"\"\"\n",
    "    Finds all raw CSVs in the folder, then loads, cleans, reshapes, and saves them.\n",
    "    This version includes specific fixes for the marketing file and date formats.\n",
    "    \"\"\"\n",
    "    # Define all the expected raw filenames\n",
    "    file_names = [\n",
    "        \"Cust By Channel-Ext.csv\", \"Cust By Channel-New.csv\", \"Email.csv\",\n",
    "        \"Media Spend by Channel.csv\",\n",
    "        \"Orders By Channel-Ext.csv\", \"Orders By Channel-New.csv\",\n",
    "        \"Returns.csv\", \"TOPSHEET.csv\", \"Web Analytics.csv\"\n",
    "    ]\n",
    "    \n",
    "    cleaned_dataframes = {}\n",
    "    errors = {}\n",
    "\n",
    "    print(f\"Starting the cleaning process for {len(file_names)} files...\")\n",
    "\n",
    "    # --- Helper Functions ---\n",
    "    def clean_currency(s):\n",
    "        if not isinstance(s, str): return pd.to_numeric(s, errors='coerce')\n",
    "        s = s.replace('$', '').replace(',', '').strip()\n",
    "        if '(' in s and ')' in s:\n",
    "            s = '-' + s.replace('(', '').replace(')', '')\n",
    "        return pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "    def clean_percentage(s):\n",
    "        if not isinstance(s, str): return pd.to_numeric(s, errors='coerce')\n",
    "        return pd.to_numeric(s.replace('%', '').replace('\"', '').strip(), errors='coerce') / 100.0\n",
    "\n",
    "    def clean_numeric(s):\n",
    "        if not isinstance(s, str): return pd.to_numeric(s, errors='coerce')\n",
    "        return pd.to_numeric(s.replace(',', '').strip(), errors='coerce')\n",
    "\n",
    "    for file_name in file_names:\n",
    "        try:\n",
    "            print(f\"--- Processing: {file_name} ---\")\n",
    "            \n",
    "            # --- File Loading and Parsing ---\n",
    "            if file_name == \"Marketing Channel Breakdown.csv\":\n",
    "                # Manual parsing for the most problematic file\n",
    "                with open(file_name, 'r', encoding='utf-8') as f:\n",
    "                    lines = f.readlines()\n",
    "                header = [h.strip() for h in lines[0].split('\\t')]\n",
    "                rows = [line.strip().split('\\t') for line in lines[1:]]\n",
    "                df = pd.DataFrame(rows, columns=header)\n",
    "            else:\n",
    "                df = pd.read_csv(file_name)\n",
    "\n",
    "            # --- Cleaning and Transformation ---\n",
    "            original_file_name = file_name\n",
    "            df.columns = [str(col).lower().replace(' ', '_').replace('-', '_') for col in df.columns]\n",
    "\n",
    "            if 'marketing_channel_breakdown' in file_name.lower():\n",
    "                df.rename(columns={df.columns[0]: 'year_period'}, inplace=True)\n",
    "                for col in ['ad_spend', 'gross_discount_(shopify)']: df[col] = df[col].apply(clean_currency)\n",
    "                for col in ['sessions', 'clicks', 'orders', 'new_customers']: df[col] = df[col].apply(clean_numeric)\n",
    "                for col in ['ctr', 'conversion_rate']: df[col] = df[col].apply(clean_percentage)\n",
    "                df['year'] = df['year_period'].apply(lambda x: str(x).split(' ')[0])\n",
    "\n",
    "            elif 'returns' in file_name.lower():\n",
    "                for col in ['gross_sales', 'discounts', 'returns', 'net_sales']: df[col] = df[col].apply(clean_currency)\n",
    "                df['month'] = pd.to_datetime(df['month'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "            elif 'email' in file_name.lower():\n",
    "                df.rename(columns={'type_(batch_marketing,_triggered,_transactional)': 'email_type'}, inplace=True)\n",
    "                for col in ['sends', 'clicks']: df[col] = df[col].apply(clean_numeric)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01', errors='coerce')\n",
    "                df = df[['date', 'email_type', 'sends', 'clicks']]\n",
    "\n",
    "            elif 'web_analytics' in file_name.lower():\n",
    "                for col in ['added_to_cart_rate', 'reached_checkout_rate', 'checkout_conversion_rate', 'conversion_rate']: df[col] = df[col].apply(clean_percentage)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01', errors='coerce')\n",
    "                df.drop(columns=['year', 'month'], inplace=True, errors='ignore')\n",
    "\n",
    "            elif 'channel' in file_name.lower() or 'topsheet' in file_name.lower():\n",
    "                id_vars = []\n",
    "                if 'topsheet' in file_name.lower():\n",
    "                    df.rename(columns={'kpi': 'metric', 'data_source': 'source'}, inplace=True)\n",
    "                    id_vars = [c for c in ['source', 'metric', 'year'] if c in df.columns]\n",
    "                else:\n",
    "                    df.rename(columns={'channel': 'channel_name'}, inplace=True)\n",
    "                    id_vars = [c for c in ['channel_name', 'year'] if c in df.columns]\n",
    "\n",
    "                month_cols = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']\n",
    "                value_vars = [col for col in month_cols if col in df.columns]\n",
    "                \n",
    "                for col in value_vars: df[col] = df[col].apply(clean_numeric)\n",
    "\n",
    "                df = df.melt(id_vars=id_vars, value_vars=value_vars, var_name='month', value_name='value')\n",
    "                \n",
    "                month_map = {name: i+1 for i, name in enumerate(month_cols)}\n",
    "                df['month_num'] = df['month'].str.lower().map(month_map)\n",
    "                df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
    "                df.dropna(subset=['year', 'month_num'], inplace=True)\n",
    "                df['year'] = df['year'].astype(int)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month_num'].astype(str) + '-01', errors='coerce')\n",
    "                df.drop(columns=['year', 'month', 'month_num'], inplace=True, errors='ignore')\n",
    "\n",
    "            cleaned_dataframes[original_file_name] = df\n",
    "            print(f\"✅ Success.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            errors[original_file_name] = str(e)\n",
    "            print(f\"❌ Error: {e}\")\n",
    "\n",
    "    print(\"\\n\\n--- Processing Summary ---\")\n",
    "    if cleaned_dataframes:\n",
    "        print(f\"Successfully processed: {len(cleaned_dataframes)} files\")\n",
    "        for f in cleaned_dataframes.keys():\n",
    "            cleaned_file_name = f\"cleaned_{f}\"\n",
    "            cleaned_dataframes[f].to_csv(cleaned_file_name, index=False)\n",
    "            print(f\"  - {f} -> Saved to {cleaned_file_name}\")\n",
    "\n",
    "    if errors:\n",
    "        print(f\"\\nFailed to process: {len(errors)} files\")\n",
    "        for f, reason in errors.items():\n",
    "            print(f\"  - {f}: {reason}\")\n",
    "    \n",
    "    return cleaned_dataframes, errors\n",
    "\n",
    "# --- Run the entire cleaning process ---\n",
    "if __name__ == '__main__':\n",
    "    cleaned_data, error_log = clean_all_data_files_final()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93ca421e-4df5-410e-8536-9d37f94a943f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the cleaning process for 1 files...\n",
      "--- Processing: Media Spend by Channel.csv ---\n",
      "✅ Success.\n",
      "\n",
      "\n",
      "--- Processing Summary ---\n",
      "Successfully processed: 1 files\n",
      "  - Media Spend by Channel.csv -> Saved to cleaned_Media Spend by Channel.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "\n",
    "def clean_all_data_files_final():\n",
    "    \"\"\"\n",
    "    Finds all raw CSVs in the folder, then loads, cleans, reshapes, and saves them.\n",
    "    This version includes specific fixes for the marketing file and date formats.\n",
    "    \"\"\"\n",
    "    # Define all the expected raw filenames\n",
    "    file_names = [\n",
    "        \"Media Spend by Channel.csv\"\n",
    "    ]\n",
    "    \n",
    "    cleaned_dataframes = {}\n",
    "    errors = {}\n",
    "\n",
    "    print(f\"Starting the cleaning process for {len(file_names)} files...\")\n",
    "\n",
    "    # --- Helper Functions ---\n",
    "    def clean_currency(s):\n",
    "        if not isinstance(s, str): return pd.to_numeric(s, errors='coerce')\n",
    "        s = s.replace('$', '').replace(',', '').strip()\n",
    "        if '(' in s and ')' in s:\n",
    "            s = '-' + s.replace('(', '').replace(')', '')\n",
    "        return pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "    def clean_percentage(s):\n",
    "        if not isinstance(s, str): return pd.to_numeric(s, errors='coerce')\n",
    "        return pd.to_numeric(s.replace('%', '').replace('\"', '').strip(), errors='coerce') / 100.0\n",
    "\n",
    "    def clean_numeric(s):\n",
    "        if not isinstance(s, str): return pd.to_numeric(s, errors='coerce')\n",
    "        return pd.to_numeric(s.replace(',', '').strip(), errors='coerce')\n",
    "\n",
    "    for file_name in file_names:\n",
    "        try:\n",
    "            print(f\"--- Processing: {file_name} ---\")\n",
    "            \n",
    "            # --- File Loading and Parsing ---\n",
    "            if file_name == \"Marketing Channel Breakdown.csv\":\n",
    "                # Manual parsing for the most problematic file\n",
    "                with open(file_name, 'r', encoding='utf-8') as f:\n",
    "                    lines = f.readlines()\n",
    "                header = [h.strip() for h in lines[0].split('\\t')]\n",
    "                rows = [line.strip().split('\\t') for line in lines[1:]]\n",
    "                df = pd.DataFrame(rows, columns=header)\n",
    "            else:\n",
    "                df = pd.read_csv(file_name)\n",
    "\n",
    "            # --- Cleaning and Transformation ---\n",
    "            original_file_name = file_name\n",
    "            df.columns = [str(col).lower().replace(' ', '_').replace('-', '_') for col in df.columns]\n",
    "\n",
    "            if 'marketing_channel_breakdown' in file_name.lower():\n",
    "                df.rename(columns={df.columns[0]: 'year_period'}, inplace=True)\n",
    "                for col in ['ad_spend', 'gross_discount_(shopify)']: df[col] = df[col].apply(clean_currency)\n",
    "                for col in ['sessions', 'clicks', 'orders', 'new_customers']: df[col] = df[col].apply(clean_numeric)\n",
    "                for col in ['ctr', 'conversion_rate']: df[col] = df[col].apply(clean_percentage)\n",
    "                df['year'] = df['year_period'].apply(lambda x: str(x).split(' ')[0])\n",
    "\n",
    "            elif 'returns' in file_name.lower():\n",
    "                for col in ['gross_sales', 'discounts', 'returns', 'net_sales']: df[col] = df[col].apply(clean_currency)\n",
    "                df['month'] = pd.to_datetime(df['month'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "            elif 'email' in file_name.lower():\n",
    "                df.rename(columns={'type_(batch_marketing,_triggered,_transactional)': 'email_type'}, inplace=True)\n",
    "                for col in ['sends', 'clicks']: df[col] = df[col].apply(clean_numeric)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01', errors='coerce')\n",
    "                df = df[['date', 'email_type', 'sends', 'clicks']]\n",
    "\n",
    "            elif 'web_analytics' in file_name.lower():\n",
    "                for col in ['added_to_cart_rate', 'reached_checkout_rate', 'checkout_conversion_rate', 'conversion_rate']: df[col] = df[col].apply(clean_percentage)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01', errors='coerce')\n",
    "                df.drop(columns=['year', 'month'], inplace=True, errors='ignore')\n",
    "\n",
    "            elif 'channel' in file_name.lower() or 'topsheet' in file_name.lower():\n",
    "                id_vars = []\n",
    "                if 'topsheet' in file_name.lower():\n",
    "                    df.rename(columns={'kpi': 'metric', 'data_source': 'source'}, inplace=True)\n",
    "                    id_vars = [c for c in ['source', 'metric', 'year'] if c in df.columns]\n",
    "                else:\n",
    "                    df.rename(columns={'channel': 'channel_name'}, inplace=True)\n",
    "                    id_vars = [c for c in ['channel_name', 'year'] if c in df.columns]\n",
    "\n",
    "                month_cols = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']\n",
    "                value_vars = [col for col in month_cols if col in df.columns]\n",
    "                \n",
    "                # CORRECTED: Use clean_currency for files like media spend that have dollar values.\n",
    "                # This is more robust than clean_numeric for these specific files.\n",
    "                for col in value_vars: df[col] = df[col].apply(clean_currency)\n",
    "\n",
    "                df = df.melt(id_vars=id_vars, value_vars=value_vars, var_name='month', value_name='value')\n",
    "                \n",
    "                month_map = {name: i+1 for i, name in enumerate(month_cols)}\n",
    "                df['month_num'] = df['month'].str.lower().map(month_map)\n",
    "                df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
    "                df.dropna(subset=['year', 'month_num'], inplace=True)\n",
    "                df['year'] = df['year'].astype(int)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month_num'].astype(str) + '-01', errors='coerce')\n",
    "                df.drop(columns=['year', 'month', 'month_num'], inplace=True, errors='ignore')\n",
    "\n",
    "            cleaned_dataframes[original_file_name] = df\n",
    "            print(f\"✅ Success.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            errors[original_file_name] = str(e)\n",
    "            print(f\"❌ Error: {e}\")\n",
    "\n",
    "    print(\"\\n\\n--- Processing Summary ---\")\n",
    "    if cleaned_dataframes:\n",
    "        print(f\"Successfully processed: {len(cleaned_dataframes)} files\")\n",
    "        for f in cleaned_dataframes.keys():\n",
    "            cleaned_file_name = f\"cleaned_{f}\"\n",
    "            cleaned_dataframes[f].to_csv(cleaned_file_name, index=False)\n",
    "            print(f\"  - {f} -> Saved to {cleaned_file_name}\")\n",
    "\n",
    "    if errors:\n",
    "        print(f\"\\nFailed to process: {len(errors)} files\")\n",
    "        for f, reason in errors.items():\n",
    "            print(f\"  - {f}: {reason}\")\n",
    "    \n",
    "    return cleaned_dataframes, errors\n",
    "\n",
    "# --- Run the entire cleaning process ---\n",
    "if __name__ == '__main__':\n",
    "    cleaned_data, error_log = clean_all_data_files_final()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18cb2a89-503e-45cf-aa70-216f18f31671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the cleaning process for 1 files...\n",
      "--- Processing: Email.csv ---\n",
      "✅ Success.\n",
      "\n",
      "\n",
      "--- Processing Summary ---\n",
      "Successfully processed: 1 files\n",
      "  - Email.csv -> Saved to cleaned_Email.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "\n",
    "def clean_all_data_files_final():\n",
    "    \"\"\"\n",
    "    Finds all raw CSVs in the folder, then loads, cleans, reshapes, and saves them.\n",
    "    This version includes specific fixes for the marketing file and date formats.\n",
    "    \"\"\"\n",
    "    # Define all the expected raw filenames\n",
    "    file_names = [\n",
    "        \"Email.csv\"\n",
    "    ]\n",
    "    \n",
    "    cleaned_dataframes = {}\n",
    "    errors = {}\n",
    "\n",
    "    print(f\"Starting the cleaning process for {len(file_names)} files...\")\n",
    "\n",
    "    # --- Helper Functions ---\n",
    "    def clean_currency(s):\n",
    "        if not isinstance(s, str): return pd.to_numeric(s, errors='coerce')\n",
    "        s = s.replace('$', '').replace(',', '').strip()\n",
    "        if '(' in s and ')' in s:\n",
    "            s = '-' + s.replace('(', '').replace(')', '')\n",
    "        return pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "    def clean_percentage(s):\n",
    "        if not isinstance(s, str): return pd.to_numeric(s, errors='coerce')\n",
    "        return pd.to_numeric(s.replace('%', '').replace('\"', '').strip(), errors='coerce') / 100.0\n",
    "\n",
    "    def clean_numeric(s):\n",
    "        if not isinstance(s, str): return pd.to_numeric(s, errors='coerce')\n",
    "        return pd.to_numeric(s.replace(',', '').strip(), errors='coerce')\n",
    "\n",
    "    for file_name in file_names:\n",
    "        try:\n",
    "            print(f\"--- Processing: {file_name} ---\")\n",
    "            \n",
    "            # --- File Loading and Parsing ---\n",
    "            if file_name == \"Marketing Channel Breakdown.csv\":\n",
    "                # Manual parsing for the most problematic file\n",
    "                with open(file_name, 'r', encoding='utf-8') as f:\n",
    "                    lines = f.readlines()\n",
    "                header = [h.strip() for h in lines[0].split('\\t')]\n",
    "                rows = [line.strip().split('\\t') for line in lines[1:]]\n",
    "                df = pd.DataFrame(rows, columns=header)\n",
    "            else:\n",
    "                df = pd.read_csv(file_name)\n",
    "\n",
    "            # --- Cleaning and Transformation ---\n",
    "            original_file_name = file_name\n",
    "            df.columns = [str(col).lower().replace(' ', '_').replace('-', '_') for col in df.columns]\n",
    "\n",
    "            if 'marketing_channel_breakdown' in file_name.lower():\n",
    "                df.rename(columns={df.columns[0]: 'year_period'}, inplace=True)\n",
    "                for col in ['ad_spend', 'gross_discount_(shopify)']: df[col] = df[col].apply(clean_currency)\n",
    "                for col in ['sessions', 'clicks', 'orders', 'new_customers']: df[col] = df[col].apply(clean_numeric)\n",
    "                for col in ['ctr', 'conversion_rate']: df[col] = df[col].apply(clean_percentage)\n",
    "                df['year'] = df['year_period'].apply(lambda x: str(x).split(' ')[0])\n",
    "\n",
    "            elif 'returns' in file_name.lower():\n",
    "                for col in ['gross_sales', 'discounts', 'returns', 'net_sales']: df[col] = df[col].apply(clean_currency)\n",
    "                df['month'] = pd.to_datetime(df['month'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "            elif 'email' in file_name.lower():\n",
    "                df.rename(columns={'type_(batch_marketing,_triggered,_transactional)': 'email_type'}, inplace=True)\n",
    "                for col in ['sends', 'clicks']: df[col] = df[col].apply(clean_numeric)\n",
    "                \n",
    "                # Remove pre-calculated \"Total\" rows to avoid double-counting\n",
    "                df = df[df['email_type'] != 'Total'].copy()\n",
    "                \n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01', errors='coerce')\n",
    "                df = df[['date', 'email_type', 'sends', 'clicks']]\n",
    "\n",
    "            elif 'web_analytics' in file_name.lower():\n",
    "                for col in ['added_to_cart_rate', 'reached_checkout_rate', 'checkout_conversion_rate', 'conversion_rate']: df[col] = df[col].apply(clean_percentage)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01', errors='coerce')\n",
    "                df.drop(columns=['year', 'month'], inplace=True, errors='ignore')\n",
    "\n",
    "            elif 'channel' in file_name.lower() or 'topsheet' in file_name.lower():\n",
    "                id_vars = []\n",
    "                if 'topsheet' in file_name.lower():\n",
    "                    df.rename(columns={'kpi': 'metric', 'data_source': 'source'}, inplace=True)\n",
    "                    id_vars = [c for c in ['source', 'metric', 'year'] if c in df.columns]\n",
    "                else:\n",
    "                    df.rename(columns={'channel': 'channel_name'}, inplace=True)\n",
    "                    id_vars = [c for c in ['channel_name', 'year'] if c in df.columns]\n",
    "\n",
    "                month_cols = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']\n",
    "                value_vars = [col for col in month_cols if col in df.columns]\n",
    "                \n",
    "                # CORRECTED: Use clean_currency for files like media spend that have dollar values.\n",
    "                # This is more robust than clean_numeric for these specific files.\n",
    "                for col in value_vars: df[col] = df[col].apply(clean_currency)\n",
    "\n",
    "                df = df.melt(id_vars=id_vars, value_vars=value_vars, var_name='month', value_name='value')\n",
    "                \n",
    "                month_map = {name: i+1 for i, name in enumerate(month_cols)}\n",
    "                df['month_num'] = df['month'].str.lower().map(month_map)\n",
    "                df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
    "                df.dropna(subset=['year', 'month_num'], inplace=True)\n",
    "                df['year'] = df['year'].astype(int)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month_num'].astype(str) + '-01', errors='coerce')\n",
    "                df.drop(columns=['year', 'month', 'month_num'], inplace=True, errors='ignore')\n",
    "\n",
    "            cleaned_dataframes[original_file_name] = df\n",
    "            print(f\"✅ Success.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            errors[original_file_name] = str(e)\n",
    "            print(f\"❌ Error: {e}\")\n",
    "\n",
    "    print(\"\\n\\n--- Processing Summary ---\")\n",
    "    if cleaned_dataframes:\n",
    "        print(f\"Successfully processed: {len(cleaned_dataframes)} files\")\n",
    "        for f in cleaned_dataframes.keys():\n",
    "            cleaned_file_name = f\"cleaned_{f}\"\n",
    "            cleaned_dataframes[f].to_csv(cleaned_file_name, index=False)\n",
    "            print(f\"  - {f} -> Saved to {cleaned_file_name}\")\n",
    "\n",
    "    if errors:\n",
    "        print(f\"\\nFailed to process: {len(errors)} files\")\n",
    "        for f, reason in errors.items():\n",
    "            print(f\"  - {f}: {reason}\")\n",
    "    \n",
    "    return cleaned_dataframes, errors\n",
    "\n",
    "# --- Run the entire cleaning process ---\n",
    "if __name__ == '__main__':\n",
    "    cleaned_data, error_log = clean_all_data_files_final()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "607cf2a3-0890-4cf6-b8d4-388ebc69165b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting the cleaning process for 1 files...\n",
      "--- Processing: Web Analytics.csv ---\n",
      "✅ Success.\n",
      "\n",
      "\n",
      "--- Processing Summary ---\n",
      "Successfully processed: 1 files\n",
      "  - Web Analytics.csv -> Saved to cleaned_Web Analytics.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import re\n",
    "\n",
    "def clean_all_data_files_final():\n",
    "    \"\"\"\n",
    "    Finds all raw CSVs in the folder, then loads, cleans, reshapes, and saves them.\n",
    "    This version includes specific fixes for the marketing file and date formats.\n",
    "    \"\"\"\n",
    "    # Define all the expected raw filenames\n",
    "    file_names = [\n",
    "        \"Web Analytics.csv\"\n",
    "    ]\n",
    "    \n",
    "    cleaned_dataframes = {}\n",
    "    errors = {}\n",
    "\n",
    "    print(f\"Starting the cleaning process for {len(file_names)} files...\")\n",
    "\n",
    "    # --- Helper Functions ---\n",
    "    def clean_currency(s):\n",
    "        if not isinstance(s, str): return pd.to_numeric(s, errors='coerce')\n",
    "        s = s.replace('$', '').replace(',', '').strip()\n",
    "        if '(' in s and ')' in s:\n",
    "            s = '-' + s.replace('(', '').replace(')', '')\n",
    "        return pd.to_numeric(s, errors='coerce')\n",
    "\n",
    "    def clean_percentage(s):\n",
    "        if not isinstance(s, str): return pd.to_numeric(s, errors='coerce')\n",
    "        return pd.to_numeric(s.replace('%', '').replace('\"', '').strip(), errors='coerce') / 100.0\n",
    "\n",
    "    def clean_numeric(s):\n",
    "        if not isinstance(s, str): return pd.to_numeric(s, errors='coerce')\n",
    "        return pd.to_numeric(s.replace(',', '').strip(), errors='coerce')\n",
    "\n",
    "    for file_name in file_names:\n",
    "        try:\n",
    "            print(f\"--- Processing: {file_name} ---\")\n",
    "            \n",
    "            # --- File Loading and Parsing ---\n",
    "            if file_name == \"Marketing Channel Breakdown.csv\":\n",
    "                # Manual parsing for the most problematic file\n",
    "                with open(file_name, 'r', encoding='utf-8') as f:\n",
    "                    lines = f.readlines()\n",
    "                header = [h.strip() for h in lines[0].split('\\t')]\n",
    "                rows = [line.strip().split('\\t') for line in lines[1:]]\n",
    "                df = pd.DataFrame(rows, columns=header)\n",
    "            else:\n",
    "                df = pd.read_csv(file_name)\n",
    "\n",
    "            # --- Cleaning and Transformation ---\n",
    "            original_file_name = file_name\n",
    "            df.columns = [str(col).lower().replace(' ', '_').replace('-', '_') for col in df.columns]\n",
    "\n",
    "            if 'marketing_channel_breakdown' in file_name.lower():\n",
    "                df.rename(columns={df.columns[0]: 'year_period'}, inplace=True)\n",
    "                for col in ['ad_spend', 'gross_discount_(shopify)']: df[col] = df[col].apply(clean_currency)\n",
    "                for col in ['sessions', 'clicks', 'orders', 'new_customers']: df[col] = df[col].apply(clean_numeric)\n",
    "                for col in ['ctr', 'conversion_rate']: df[col] = df[col].apply(clean_percentage)\n",
    "                df['year'] = df['year_period'].apply(lambda x: str(x).split(' ')[0])\n",
    "\n",
    "            elif 'returns' in file_name.lower():\n",
    "                for col in ['gross_sales', 'discounts', 'returns', 'net_sales']: df[col] = df[col].apply(clean_currency)\n",
    "                df['month'] = pd.to_datetime(df['month'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "            elif 'email' in file_name.lower():\n",
    "                df.rename(columns={'type_(batch_marketing,_triggered,_transactional)': 'email_type'}, inplace=True)\n",
    "                for col in ['sends', 'clicks']: df[col] = df[col].apply(clean_numeric)\n",
    "                \n",
    "                # Remove pre-calculated \"Total\" rows to avoid double-counting\n",
    "                df = df[df['email_type'] != 'Total'].copy()\n",
    "                \n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01', errors='coerce')\n",
    "                df = df[['date', 'email_type', 'sends', 'clicks']]\n",
    "\n",
    "            elif 'web_analytics' in file_name.lower():\n",
    "                for col in ['added_to_cart_rate', 'reached_checkout_rate', 'checkout_conversion_rate', 'conversion_rate']: df[col] = df[col].apply(clean_percentage)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01', errors='coerce')\n",
    "                df.drop(columns=['year', 'month'], inplace=True, errors='ignore')\n",
    "\n",
    "            elif 'channel' in file_name.lower() or 'topsheet' in file_name.lower():\n",
    "                id_vars = []\n",
    "                if 'topsheet' in file_name.lower():\n",
    "                    df.rename(columns={'kpi': 'metric', 'data_source': 'source'}, inplace=True)\n",
    "                    id_vars = [c for c in ['source', 'metric', 'year'] if c in df.columns]\n",
    "                else:\n",
    "                    df.rename(columns={'channel': 'channel_name'}, inplace=True)\n",
    "                    id_vars = [c for c in ['channel_name', 'year'] if c in df.columns]\n",
    "\n",
    "                month_cols = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']\n",
    "                value_vars = [col for col in month_cols if col in df.columns]\n",
    "                \n",
    "                # CORRECTED: Use clean_currency for files like media spend that have dollar values.\n",
    "                # This is more robust than clean_numeric for these specific files.\n",
    "                for col in value_vars: df[col] = df[col].apply(clean_currency)\n",
    "\n",
    "                df = df.melt(id_vars=id_vars, value_vars=value_vars, var_name='month', value_name='value')\n",
    "                \n",
    "                month_map = {name: i+1 for i, name in enumerate(month_cols)}\n",
    "                df['month_num'] = df['month'].str.lower().map(month_map)\n",
    "                df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
    "                df.dropna(subset=['year', 'month_num'], inplace=True)\n",
    "                df['year'] = df['year'].astype(int)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month_num'].astype(str) + '-01', errors='coerce')\n",
    "                df.drop(columns=['year', 'month', 'month_num'], inplace=True, errors='ignore')\n",
    "\n",
    "            cleaned_dataframes[original_file_name] = df\n",
    "            print(f\"✅ Success.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            errors[original_file_name] = str(e)\n",
    "            print(f\"❌ Error: {e}\")\n",
    "\n",
    "    print(\"\\n\\n--- Processing Summary ---\")\n",
    "    if cleaned_dataframes:\n",
    "        print(f\"Successfully processed: {len(cleaned_dataframes)} files\")\n",
    "        for f in cleaned_dataframes.keys():\n",
    "            cleaned_file_name = f\"cleaned_{f}\"\n",
    "            cleaned_dataframes[f].to_csv(cleaned_file_name, index=False)\n",
    "            print(f\"  - {f} -> Saved to {cleaned_file_name}\")\n",
    "\n",
    "    if errors:\n",
    "        print(f\"\\nFailed to process: {len(errors)} files\")\n",
    "        for f, reason in errors.items():\n",
    "            print(f\"  - {f}: {reason}\")\n",
    "    \n",
    "    return cleaned_dataframes, errors\n",
    "\n",
    "# --- Run the entire cleaning process ---\n",
    "if __name__ == '__main__':\n",
    "    cleaned_data, error_log = clean_all_data_files_final()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ac11d80d-28ca-4825-9a1b-372d2e0244c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 files to process...\n",
      "--- Processing: Cleaned_Marketing Channel Breakdown.csv ---\n",
      "❌ Error: \"The following id_vars or value_vars are not present in the DataFrame: ['channel_name']\"\n",
      "--- Processing: Cust By Channel-Ext.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Cust By Channel-New.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Email.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Marketing Channel Breakdown.csv ---\n",
      "❌ Error: \"The following id_vars or value_vars are not present in the DataFrame: ['channel_name', 'year']\"\n",
      "--- Processing: Media Spend by Channel.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Orders By Channel-Ext.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Orders By Channel-New.csv ---\n",
      "✅ Success.\n",
      "--- Processing: Returns.csv ---\n",
      "✅ Success.\n",
      "--- Processing: TOPSHEET.csv ---\n",
      "❌ Error: \"The following id_vars or value_vars are not present in the DataFrame: ['source', 'metric', 'year']\"\n",
      "--- Processing: Web Analytics.csv ---\n",
      "✅ Success.\n",
      "\n",
      "\n",
      "--- Processing Summary ---\n",
      "Successfully processed: 8 files\n"
     ]
    },
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: 'cleaned_Cust By Channel-Ext.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 131\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[38;5;66;03m# --- Run the script ---\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 131\u001b[0m     cleaned_data, error_log \u001b[38;5;241m=\u001b[39m \u001b[43mclean_and_process_all_files\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    133\u001b[0m     \u001b[38;5;66;03m# As an example, display the first 5 rows of a cleaned, reshaped file\u001b[39;00m\n\u001b[0;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMedia Spend by Channel.csv\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m cleaned_data:\n",
      "Cell \u001b[1;32mIn[15], line 119\u001b[0m, in \u001b[0;36mclean_and_process_all_files\u001b[1;34m()\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m cleaned_dataframes\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    118\u001b[0m         cleaned_file_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcleaned_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 119\u001b[0m         \u001b[43mcleaned_dataframes\u001b[49m\u001b[43m[\u001b[49m\u001b[43mf\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcleaned_file_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    120\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m  - \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m -> Saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcleaned_file_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m errors:\n",
      "File \u001b[1;32mD:\\Fiverr\\DTC_Analytics_Project\\venv\\lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mD:\\Fiverr\\DTC_Analytics_Project\\venv\\lib\\site-packages\\pandas\\core\\generic.py:3986\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3975\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3977\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3978\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3979\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3983\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3984\u001b[0m )\n\u001b[1;32m-> 3986\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameRenderer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_csv\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3987\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath_or_buf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3988\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlineterminator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlineterminator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3989\u001b[0m \u001b[43m    \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3990\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3991\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3992\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3993\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquoting\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquoting\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3994\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mindex_label\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunksize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mquotechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquotechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3999\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdate_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdate_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4000\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdoublequote\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdoublequote\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4001\u001b[0m \u001b[43m    \u001b[49m\u001b[43mescapechar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mescapechar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4002\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   4003\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mD:\\Fiverr\\DTC_Analytics_Project\\venv\\lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m \u001b[43mcsv_formatter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mD:\\Fiverr\\DTC_Analytics_Project\\venv\\lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompression\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    258\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mD:\\Fiverr\\DTC_Analytics_Project\\venv\\lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'cleaned_Cust By Channel-Ext.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "def clean_and_process_all_files():\n",
    "    \"\"\"\n",
    "    Finds all relevant CSVs in the folder, then loads, cleans, and processes them.\n",
    "    - Cleans currency and percentage strings.\n",
    "    - Reshapes wide-format data to long format.\n",
    "    - Standardizes column names.\n",
    "    - Handles file not found errors gracefully.\n",
    "    - Saves cleaned files to new CSVs.\n",
    "    \"\"\"\n",
    "    # Use glob to find the files in the current directory\n",
    "    file_names = [f for f in glob.glob(\"*.csv\") if not f.startswith('cleaned_')]\n",
    "    \n",
    "    cleaned_dataframes = {}\n",
    "    errors = {}\n",
    "\n",
    "    print(f\"Found {len(file_names)} files to process...\")\n",
    "\n",
    "    # --- Helper Functions ---\n",
    "    def clean_currency(s):\n",
    "        if isinstance(s, str):\n",
    "            s = s.replace('$', '').replace(',', '')\n",
    "            if '(' in s and ')' in s:\n",
    "                s = '-' + s.replace('(', '').replace(')', '')\n",
    "            return pd.to_numeric(s, errors='coerce')\n",
    "        return s\n",
    "\n",
    "    def clean_numeric_string(s):\n",
    "        if isinstance(s, str):\n",
    "            return pd.to_numeric(s.replace(',', ''), errors='coerce')\n",
    "        return s\n",
    "\n",
    "    def clean_percentage(s):\n",
    "        if isinstance(s, str):\n",
    "            return pd.to_numeric(s.replace('%', ''), errors='coerce') / 100.0\n",
    "        return s\n",
    "\n",
    "    for file_name in file_names:\n",
    "        try:\n",
    "            print(f\"--- Processing: {file_name} ---\")\n",
    "            \n",
    "            separator = '\\t' if file_name == \"TOPSHEET.csv\" else ','\n",
    "            df = pd.read_csv(file_name, sep=separator)\n",
    "            \n",
    "            original_file_name = file_name # Keep track of the original name\n",
    "            \n",
    "            # Standardize column names\n",
    "            df.columns = [str(col).lower().replace(' ', '_').replace('-', '_') for col in df.columns]\n",
    "\n",
    "            if 'returns' in file_name.lower():\n",
    "                for col in ['gross_sales', 'discounts', 'returns', 'net_sales']:\n",
    "                    df[col] = df[col].apply(clean_currency)\n",
    "                df['month'] = pd.to_datetime(df['month'], format='%m/%d/%Y', errors='coerce')\n",
    "\n",
    "            elif 'email' in file_name.lower():\n",
    "                df.rename(columns={'type_(batch_marketing,_triggered,_transactional)': 'email_type'}, inplace=True)\n",
    "                df['sends'] = df['sends'].apply(clean_numeric_string)\n",
    "                df['clicks'] = df['clicks'].apply(clean_numeric_string)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01', errors='coerce')\n",
    "                df = df[['date', 'email_type', 'sends', 'clicks']]\n",
    "            \n",
    "            elif 'web_analytics' in file_name.lower():\n",
    "                for col in ['added_to_cart_rate', 'reached_checkout_rate', 'checkout_conversion_rate', 'conversion_rate']:\n",
    "                    df[col] = df[col].apply(clean_percentage)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month'].astype(str) + '-01', errors='coerce')\n",
    "                df.drop(columns=['year', 'month'], inplace=True, errors='ignore')\n",
    "\n",
    "            elif 'channel' in file_name.lower() or 'topsheet' in file_name.lower():\n",
    "                if 'topsheet' in file_name.lower():\n",
    "                    df.rename(columns={'kpi': 'metric', 'data_source': 'source'}, inplace=True)\n",
    "                    id_vars = ['source', 'metric', 'year']\n",
    "                else:\n",
    "                    df.rename(columns={'channel': 'channel_name'}, inplace=True)\n",
    "                    id_vars = ['channel_name', 'year']\n",
    "                \n",
    "                month_cols = ['january', 'february', 'march', 'april', 'may', 'june', 'july', 'august', 'september', 'october', 'november', 'december']\n",
    "                value_vars = [col for col in month_cols if col in df.columns]\n",
    "                \n",
    "                for col in value_vars:\n",
    "                    df[col] = df[col].astype(str).str.replace(',', '').str.replace('$', '').str.replace('%', '')\n",
    "                    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "                df = df.melt(id_vars=id_vars, value_vars=value_vars, var_name='month', value_name='value')\n",
    "                \n",
    "                month_map = {name: i+1 for i, name in enumerate(month_cols)}\n",
    "                df['month_num'] = df['month'].str.lower().map(month_map)\n",
    "                df['year'] = pd.to_numeric(df['year'], errors='coerce')\n",
    "                df.dropna(subset=['year', 'month_num'], inplace=True)\n",
    "                df['year'] = df['year'].astype(int)\n",
    "                df['date'] = pd.to_datetime(df['year'].astype(str) + '-' + df['month_num'].astype(str) + '-01', errors='coerce')\n",
    "                df.drop(columns=['year', 'month', 'month_num'], inplace=True, errors='ignore')\n",
    "            \n",
    "            elif 'marketing_channel_breakdown' in file_name.lower():\n",
    "                 # This file might have a year as the first column, let's rename it\n",
    "                df.rename(columns={df.columns[0]: 'year'}, inplace=True)\n",
    "                # Add cleaning logic for its specific currency/numeric columns if needed\n",
    "                for col in ['ad_spend', 'gross_discount_(shopify)', 'sessions', 'clicks', 'orders', 'new_customers']:\n",
    "                    if col in df.columns:\n",
    "                        df[col] = df[col].apply(clean_numeric_string)\n",
    "                for col in ['ctr', 'conversion_rate']:\n",
    "                     if col in df.columns:\n",
    "                        df[col] = df[col].apply(clean_percentage)\n",
    "\n",
    "            cleaned_dataframes[original_file_name] = df\n",
    "            print(f\"✅ Success.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            errors[original_file_name] = str(e)\n",
    "            print(f\"❌ Error: {e}\")\n",
    "\n",
    "    print(\"\\n\\n--- Processing Summary ---\")\n",
    "    if cleaned_dataframes:\n",
    "        print(f\"Successfully processed: {len(cleaned_dataframes)} files\")\n",
    "        for f in cleaned_dataframes.keys():\n",
    "            cleaned_file_name = f\"cleaned_{f}\"\n",
    "            cleaned_dataframes[f].to_csv(cleaned_file_name, index=False)\n",
    "            print(f\"  - {f} -> Saved to {cleaned_file_name}\")\n",
    "\n",
    "    if errors:\n",
    "        print(f\"\\nFailed to process: {len(errors)} files\")\n",
    "        for f, reason in errors.items():\n",
    "            print(f\"  - {f}: {reason}\")\n",
    "    \n",
    "    return cleaned_dataframes, errors\n",
    "\n",
    "# --- Run the script ---\n",
    "if __name__ == '__main__':\n",
    "    cleaned_data, error_log = clean_and_process_all_files()\n",
    "\n",
    "    # As an example, display the first 5 rows of a cleaned, reshaped file\n",
    "    if 'Media Spend by Channel.csv' in cleaned_data:\n",
    "        print(\"\\n--- Sample of Cleaned Data (Media Spend by Channel.csv) ---\")\n",
    "        print(cleaned_data['Media Spend by Channel.csv'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc2c1ab-582f-4654-b861-87ee5fb800de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DTC Analytics)",
   "language": "python",
   "name": "dtc_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
